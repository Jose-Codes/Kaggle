{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(os.getcwd(), \"data\", \"train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(os.getcwd(), \"data\", \"test.csv\"))\n",
    "test_ids = test_data[\"PassengerId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   8693 non-null   object \n",
      " 1   HomePlanet    8492 non-null   object \n",
      " 2   CryoSleep     8476 non-null   object \n",
      " 3   Cabin         8494 non-null   object \n",
      " 4   Destination   8511 non-null   object \n",
      " 5   Age           8514 non-null   float64\n",
      " 6   VIP           8490 non-null   object \n",
      " 7   RoomService   8512 non-null   float64\n",
      " 8   FoodCourt     8510 non-null   float64\n",
      " 9   ShoppingMall  8485 non-null   float64\n",
      " 10  Spa           8510 non-null   float64\n",
      " 11  VRDeck        8505 non-null   float64\n",
      " 12  Name          8493 non-null   object \n",
      " 13  Transported   8693 non-null   bool   \n",
      "dtypes: bool(1), float64(6), object(7)\n",
      "memory usage: 891.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "HomePlanet      201\n",
       "CryoSleep       217\n",
       "Cabin           199\n",
       "Destination     182\n",
       "Age             179\n",
       "VIP             203\n",
       "RoomService     181\n",
       "FoodCourt       183\n",
       "ShoppingMall    208\n",
       "Spa             183\n",
       "VRDeck          188\n",
       "Name            200\n",
       "Transported       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(data):\n",
    "    \"\"\"\n",
    "    Description: This function will do some data preprocessing, such as replace missing values in the inputed dataframe.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame) : A pandas dataframe containing information about passengers.\n",
    "    Returns:\n",
    "        data (pd.Dataframe) : Returns the cleaned data frame.\n",
    "    \"\"\"\n",
    "\n",
    "    data = data.drop([\"PassengerId\", \"Cabin\", \"Name\"], axis=1) # Drop columns that will likely not help our prediction\n",
    "\n",
    "    cols = [\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"Age\"] # All these columns have some missing values and they are numerical\n",
    "    for col in cols:\n",
    "        data[col].fillna(data[col].median(), inplace=True) # This will replace the null values with the median value of that column\n",
    "\n",
    "    cols = [\"HomePlanet\", \"Destination\"]\n",
    "    for col in cols:\n",
    "        data[col].fillna(\"Unkown\", inplace=True) # We will just fill the missing data values with the string \"Unknown\"\n",
    "    \n",
    "    cols = [\"CryoSleep\", \"VIP\"]\n",
    "    for col in cols:\n",
    "        data[col].fillna(value=bool(False), inplace=True)\n",
    "    \n",
    "    # data.dropna(axis=0, how='any', thresh=None, inplace=True) # Drop any row that has missing values\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect/clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = clean(train_data)\n",
    "test_data = clean(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HomePlanet  CryoSleep  Destination   Age    VIP  RoomService  FoodCourt  \\\n",
       "0     Europa      False  TRAPPIST-1e  39.0  False          0.0        0.0   \n",
       "1      Earth      False  TRAPPIST-1e  24.0  False        109.0        9.0   \n",
       "2     Europa      False  TRAPPIST-1e  58.0   True         43.0     3576.0   \n",
       "3     Europa      False  TRAPPIST-1e  33.0  False          0.0     1283.0   \n",
       "4      Earth      False  TRAPPIST-1e  16.0  False        303.0       70.0   \n",
       "\n",
       "   ShoppingMall     Spa  VRDeck  Transported  \n",
       "0           0.0     0.0     0.0        False  \n",
       "1          25.0   549.0    44.0         True  \n",
       "2           0.0  6715.0    49.0        False  \n",
       "3         371.0  3329.0   193.0        False  \n",
       "4         151.0   565.0     2.0         True  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HomePlanet  CryoSleep  Destination   Age    VIP  RoomService  FoodCourt  \\\n",
       "0      Earth       True  TRAPPIST-1e  27.0  False          0.0        0.0   \n",
       "1      Earth      False  TRAPPIST-1e  19.0  False          0.0        9.0   \n",
       "2     Europa       True  55 Cancri e  31.0  False          0.0        0.0   \n",
       "3     Europa      False  TRAPPIST-1e  38.0  False          0.0     6652.0   \n",
       "4      Earth      False  TRAPPIST-1e  20.0  False         10.0        0.0   \n",
       "\n",
       "   ShoppingMall     Spa  VRDeck  \n",
       "0           0.0     0.0     0.0  \n",
       "1           0.0  2823.0     0.0  \n",
       "2           0.0     0.0     0.0  \n",
       "3           0.0   181.0   585.0  \n",
       "4         635.0     0.0     0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HomePlanet      0\n",
       "CryoSleep       0\n",
       "Destination     0\n",
       "Age             0\n",
       "VIP             0\n",
       "RoomService     0\n",
       "FoodCourt       0\n",
       "ShoppingMall    0\n",
       "Spa             0\n",
       "VRDeck          0\n",
       "Transported     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   HomePlanet    8693 non-null   object \n",
      " 1   CryoSleep     8693 non-null   bool   \n",
      " 2   Destination   8693 non-null   object \n",
      " 3   Age           8693 non-null   float64\n",
      " 4   VIP           8693 non-null   bool   \n",
      " 5   RoomService   8693 non-null   float64\n",
      " 6   FoodCourt     8693 non-null   float64\n",
      " 7   ShoppingMall  8693 non-null   float64\n",
      " 8   Spa           8693 non-null   float64\n",
      " 9   VRDeck        8693 non-null   float64\n",
      " 10  Transported   8693 non-null   bool   \n",
      "dtypes: bool(3), float64(6), object(2)\n",
      "memory usage: 568.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4277 entries, 0 to 4276\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   HomePlanet    4277 non-null   object \n",
      " 1   CryoSleep     4277 non-null   bool   \n",
      " 2   Destination   4277 non-null   object \n",
      " 3   Age           4277 non-null   float64\n",
      " 4   VIP           4277 non-null   bool   \n",
      " 5   RoomService   4277 non-null   float64\n",
      " 6   FoodCourt     4277 non-null   float64\n",
      " 7   ShoppingMall  4277 non-null   float64\n",
      " 8   Spa           4277 non-null   float64\n",
      " 9   VRDeck        4277 non-null   float64\n",
      "dtypes: bool(2), float64(6), object(2)\n",
      "memory usage: 275.8+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.bool_"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data[\"CryoSleep\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomePlanet, ['Earth' 'Europa' 'Mars' 'Unkown']\n",
      "CryoSleep, [False  True]\n",
      "Destination, ['55 Cancri e' 'PSO J318.5-22' 'TRAPPIST-1e' 'Unkown']\n",
      "VIP, [False  True]\n"
     ]
    }
   ],
   "source": [
    "# Now we need to encode the String labels into numbers, so True/False will be 1/0\n",
    "cols = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"VIP\"]\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "for col in cols:\n",
    "    train_data[col] = label_encoder.fit_transform(train_data[col])\n",
    "    test_data[col] = label_encoder.fit_transform(test_data[col]) # We want to use the same trasnsformation from the training set\n",
    "    print(f\"{col}, {label_encoder.classes_}\")\n",
    "\n",
    "# train_data[\"Transported\"] = label_encoder.fit_transform(train_data[\"Transported\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HomePlanet  CryoSleep  Destination   Age  VIP  RoomService  FoodCourt  \\\n",
       "0           1          0            2  39.0    0          0.0        0.0   \n",
       "1           0          0            2  24.0    0        109.0        9.0   \n",
       "2           1          0            2  58.0    1         43.0     3576.0   \n",
       "3           1          0            2  33.0    0          0.0     1283.0   \n",
       "4           0          0            2  16.0    0        303.0       70.0   \n",
       "\n",
       "   ShoppingMall     Spa  VRDeck  Transported  \n",
       "0           0.0     0.0     0.0        False  \n",
       "1          25.0   549.0    44.0         True  \n",
       "2           0.0  6715.0    49.0        False  \n",
       "3         371.0  3329.0   193.0        False  \n",
       "4         151.0   565.0     2.0         True  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is all numerical so now we can go into training our model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select/Train/Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data[\"Transported\"]\n",
    "x = train_data.drop(\"Transported\", axis=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(random_state=0, max_iter=10000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logistic_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression validation Accuracy Score: 0.7740\n"
     ]
    }
   ],
   "source": [
    "print(f\"Logistic regression validation Accuracy Score: {accuracy_score(y_val, predictions):0.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_preds = logistic_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\"PassengerId\": test_ids.values,\n",
    "                              \"Transported\": submission_preds,\n",
    "                            })\n",
    "\n",
    "submission_df.to_csv(\"Submission.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try grid search to see if we can make it better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_classifier = RandomForestClassifier(random_state=42)\n",
    "xgb_classfier = XGBClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "                \"random_forest_classifier\" : {\n",
    "                    \"n_estimators\": [25, 50, 100, 200, 250],\n",
    "                    \"max_depth\": [2, 4, 8, 16],\n",
    "                    \"min_samples_split\": [2, 4, 8, 16, 32]\n",
    "                },\n",
    "                \"xgboost_classifier\" : {\n",
    "                    \"n_estimators\": [25, 50, 100, 200, 250],\n",
    "                    \"max_depth\": [2, 4, 8, 16],\n",
    "                    \"gamma\": [0.01, 0.1], # Minimum amount of loss (info gain) required to keep splitting\n",
    "                    \"learning_rate\": [0.001, 0.01, 0.1, 1]\n",
    "                }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_forest = GridSearchCV(estimator=random_forest_classifier,\n",
    "                                  param_grid=search_space[\"random_forest_classifier\"],\n",
    "                                  scoring=[\"neg_log_loss\", \"f1\"],\n",
    "                                  refit=\"neg_log_loss\",\n",
    "                                  cv=5, # k-fold cross validation\n",
    "                                  verbose=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 1/5] END max_depth=2, min_samples_split=2, n_estimators=25; f1: (test=0.711) neg_log_loss: (test=-0.546) total time=   0.0s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=2, n_estimators=25; f1: (test=0.687) neg_log_loss: (test=-0.554) total time=   0.0s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=2, n_estimators=25; f1: (test=0.700) neg_log_loss: (test=-0.549) total time=   0.0s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=2, n_estimators=25; f1: (test=0.697) neg_log_loss: (test=-0.549) total time=   0.0s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=2, n_estimators=25; f1: (test=0.721) neg_log_loss: (test=-0.531) total time=   0.0s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=2, n_estimators=50; f1: (test=0.714) neg_log_loss: (test=-0.547) total time=   0.0s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=2, n_estimators=50; f1: (test=0.694) neg_log_loss: (test=-0.554) total time=   0.0s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=2, n_estimators=50; f1: (test=0.712) neg_log_loss: (test=-0.550) total time=   0.0s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=2, n_estimators=50; f1: (test=0.712) neg_log_loss: (test=-0.548) total time=   0.0s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=2, n_estimators=50; f1: (test=0.736) neg_log_loss: (test=-0.532) total time=   0.0s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=2, n_estimators=100; f1: (test=0.713) neg_log_loss: (test=-0.549) total time=   0.2s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=2, n_estimators=100; f1: (test=0.697) neg_log_loss: (test=-0.555) total time=   0.1s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=2, n_estimators=100; f1: (test=0.722) neg_log_loss: (test=-0.553) total time=   0.2s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=2, n_estimators=100; f1: (test=0.715) neg_log_loss: (test=-0.551) total time=   0.1s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=2, n_estimators=100; f1: (test=0.737) neg_log_loss: (test=-0.535) total time=   0.1s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=2, n_estimators=200; f1: (test=0.724) neg_log_loss: (test=-0.547) total time=   0.3s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=2, n_estimators=200; f1: (test=0.698) neg_log_loss: (test=-0.553) total time=   0.3s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=2, n_estimators=200; f1: (test=0.723) neg_log_loss: (test=-0.551) total time=   0.3s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=2, n_estimators=200; f1: (test=0.724) neg_log_loss: (test=-0.548) total time=   0.3s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=2, n_estimators=200; f1: (test=0.739) neg_log_loss: (test=-0.532) total time=   0.3s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=2, n_estimators=250; f1: (test=0.723) neg_log_loss: (test=-0.546) total time=   0.4s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=2, n_estimators=250; f1: (test=0.698) neg_log_loss: (test=-0.553) total time=   0.4s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=2, n_estimators=250; f1: (test=0.723) neg_log_loss: (test=-0.551) total time=   0.4s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=2, n_estimators=250; f1: (test=0.724) neg_log_loss: (test=-0.549) total time=   0.4s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=2, n_estimators=250; f1: (test=0.740) neg_log_loss: (test=-0.532) total time=   0.4s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=4, n_estimators=25; f1: (test=0.711) neg_log_loss: (test=-0.546) total time=   0.0s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=4, n_estimators=25; f1: (test=0.687) neg_log_loss: (test=-0.554) total time=   0.0s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=4, n_estimators=25; f1: (test=0.700) neg_log_loss: (test=-0.549) total time=   0.0s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=4, n_estimators=25; f1: (test=0.697) neg_log_loss: (test=-0.549) total time=   0.0s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=4, n_estimators=25; f1: (test=0.721) neg_log_loss: (test=-0.531) total time=   0.0s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=4, n_estimators=50; f1: (test=0.714) neg_log_loss: (test=-0.547) total time=   0.0s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=4, n_estimators=50; f1: (test=0.694) neg_log_loss: (test=-0.554) total time=   0.0s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=4, n_estimators=50; f1: (test=0.712) neg_log_loss: (test=-0.550) total time=   0.0s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=4, n_estimators=50; f1: (test=0.712) neg_log_loss: (test=-0.548) total time=   0.0s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=4, n_estimators=50; f1: (test=0.736) neg_log_loss: (test=-0.532) total time=   0.0s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=4, n_estimators=100; f1: (test=0.713) neg_log_loss: (test=-0.549) total time=   0.1s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=4, n_estimators=100; f1: (test=0.697) neg_log_loss: (test=-0.555) total time=   0.1s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=4, n_estimators=100; f1: (test=0.722) neg_log_loss: (test=-0.553) total time=   0.1s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=4, n_estimators=100; f1: (test=0.715) neg_log_loss: (test=-0.551) total time=   0.1s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=4, n_estimators=100; f1: (test=0.737) neg_log_loss: (test=-0.535) total time=   0.1s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=4, n_estimators=200; f1: (test=0.724) neg_log_loss: (test=-0.547) total time=   0.3s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=4, n_estimators=200; f1: (test=0.698) neg_log_loss: (test=-0.553) total time=   0.3s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=4, n_estimators=200; f1: (test=0.723) neg_log_loss: (test=-0.551) total time=   0.3s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=4, n_estimators=200; f1: (test=0.724) neg_log_loss: (test=-0.548) total time=   0.3s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=4, n_estimators=200; f1: (test=0.739) neg_log_loss: (test=-0.532) total time=   0.3s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=4, n_estimators=250; f1: (test=0.723) neg_log_loss: (test=-0.546) total time=   0.4s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=4, n_estimators=250; f1: (test=0.698) neg_log_loss: (test=-0.553) total time=   0.5s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=4, n_estimators=250; f1: (test=0.723) neg_log_loss: (test=-0.551) total time=   0.4s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=4, n_estimators=250; f1: (test=0.724) neg_log_loss: (test=-0.549) total time=   0.4s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=4, n_estimators=250; f1: (test=0.740) neg_log_loss: (test=-0.532) total time=   0.4s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=8, n_estimators=25; f1: (test=0.711) neg_log_loss: (test=-0.546) total time=   0.0s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=8, n_estimators=25; f1: (test=0.687) neg_log_loss: (test=-0.554) total time=   0.0s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=8, n_estimators=25; f1: (test=0.700) neg_log_loss: (test=-0.549) total time=   0.0s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=8, n_estimators=25; f1: (test=0.697) neg_log_loss: (test=-0.549) total time=   0.0s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=8, n_estimators=25; f1: (test=0.721) neg_log_loss: (test=-0.531) total time=   0.0s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=8, n_estimators=50; f1: (test=0.714) neg_log_loss: (test=-0.547) total time=   0.0s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=8, n_estimators=50; f1: (test=0.694) neg_log_loss: (test=-0.554) total time=   0.0s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=8, n_estimators=50; f1: (test=0.712) neg_log_loss: (test=-0.550) total time=   0.0s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=8, n_estimators=50; f1: (test=0.712) neg_log_loss: (test=-0.548) total time=   0.0s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=8, n_estimators=50; f1: (test=0.736) neg_log_loss: (test=-0.532) total time=   0.0s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=8, n_estimators=100; f1: (test=0.713) neg_log_loss: (test=-0.549) total time=   0.1s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=8, n_estimators=100; f1: (test=0.697) neg_log_loss: (test=-0.555) total time=   0.1s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=8, n_estimators=100; f1: (test=0.722) neg_log_loss: (test=-0.553) total time=   0.1s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=8, n_estimators=100; f1: (test=0.715) neg_log_loss: (test=-0.551) total time=   0.1s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=8, n_estimators=100; f1: (test=0.737) neg_log_loss: (test=-0.535) total time=   0.1s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=8, n_estimators=200; f1: (test=0.724) neg_log_loss: (test=-0.547) total time=   0.3s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=8, n_estimators=200; f1: (test=0.698) neg_log_loss: (test=-0.553) total time=   0.3s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=8, n_estimators=200; f1: (test=0.723) neg_log_loss: (test=-0.551) total time=   0.3s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=8, n_estimators=200; f1: (test=0.724) neg_log_loss: (test=-0.548) total time=   0.3s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=8, n_estimators=200; f1: (test=0.739) neg_log_loss: (test=-0.532) total time=   0.3s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=8, n_estimators=250; f1: (test=0.723) neg_log_loss: (test=-0.546) total time=   0.4s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=8, n_estimators=250; f1: (test=0.698) neg_log_loss: (test=-0.553) total time=   0.4s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=8, n_estimators=250; f1: (test=0.723) neg_log_loss: (test=-0.551) total time=   0.4s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=8, n_estimators=250; f1: (test=0.724) neg_log_loss: (test=-0.549) total time=   0.4s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=8, n_estimators=250; f1: (test=0.740) neg_log_loss: (test=-0.532) total time=   0.4s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=16, n_estimators=25; f1: (test=0.711) neg_log_loss: (test=-0.546) total time=   0.0s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=16, n_estimators=25; f1: (test=0.687) neg_log_loss: (test=-0.554) total time=   0.0s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=16, n_estimators=25; f1: (test=0.700) neg_log_loss: (test=-0.549) total time=   0.0s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=16, n_estimators=25; f1: (test=0.697) neg_log_loss: (test=-0.549) total time=   0.0s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=16, n_estimators=25; f1: (test=0.721) neg_log_loss: (test=-0.531) total time=   0.0s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=16, n_estimators=50; f1: (test=0.714) neg_log_loss: (test=-0.547) total time=   0.0s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=16, n_estimators=50; f1: (test=0.694) neg_log_loss: (test=-0.554) total time=   0.0s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=16, n_estimators=50; f1: (test=0.712) neg_log_loss: (test=-0.550) total time=   0.0s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=16, n_estimators=50; f1: (test=0.712) neg_log_loss: (test=-0.548) total time=   0.0s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=16, n_estimators=50; f1: (test=0.736) neg_log_loss: (test=-0.532) total time=   0.0s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=16, n_estimators=100; f1: (test=0.713) neg_log_loss: (test=-0.549) total time=   0.1s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=16, n_estimators=100; f1: (test=0.697) neg_log_loss: (test=-0.555) total time=   0.1s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=16, n_estimators=100; f1: (test=0.722) neg_log_loss: (test=-0.553) total time=   0.1s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=16, n_estimators=100; f1: (test=0.715) neg_log_loss: (test=-0.551) total time=   0.1s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=16, n_estimators=100; f1: (test=0.737) neg_log_loss: (test=-0.535) total time=   0.1s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=16, n_estimators=200; f1: (test=0.724) neg_log_loss: (test=-0.547) total time=   0.3s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=16, n_estimators=200; f1: (test=0.698) neg_log_loss: (test=-0.553) total time=   0.3s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=16, n_estimators=200; f1: (test=0.723) neg_log_loss: (test=-0.551) total time=   0.3s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=16, n_estimators=200; f1: (test=0.724) neg_log_loss: (test=-0.548) total time=   0.3s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=16, n_estimators=200; f1: (test=0.739) neg_log_loss: (test=-0.532) total time=   0.3s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=16, n_estimators=250; f1: (test=0.723) neg_log_loss: (test=-0.546) total time=   0.4s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=16, n_estimators=250; f1: (test=0.698) neg_log_loss: (test=-0.553) total time=   0.4s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=16, n_estimators=250; f1: (test=0.723) neg_log_loss: (test=-0.551) total time=   0.4s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=16, n_estimators=250; f1: (test=0.724) neg_log_loss: (test=-0.549) total time=   0.4s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=16, n_estimators=250; f1: (test=0.740) neg_log_loss: (test=-0.532) total time=   0.5s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=32, n_estimators=25; f1: (test=0.711) neg_log_loss: (test=-0.546) total time=   0.0s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=32, n_estimators=25; f1: (test=0.687) neg_log_loss: (test=-0.554) total time=   0.0s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=32, n_estimators=25; f1: (test=0.700) neg_log_loss: (test=-0.549) total time=   0.0s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=32, n_estimators=25; f1: (test=0.697) neg_log_loss: (test=-0.549) total time=   0.0s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=32, n_estimators=25; f1: (test=0.721) neg_log_loss: (test=-0.531) total time=   0.0s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=32, n_estimators=50; f1: (test=0.714) neg_log_loss: (test=-0.547) total time=   0.0s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=32, n_estimators=50; f1: (test=0.694) neg_log_loss: (test=-0.554) total time=   0.0s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=32, n_estimators=50; f1: (test=0.712) neg_log_loss: (test=-0.550) total time=   0.0s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=32, n_estimators=50; f1: (test=0.712) neg_log_loss: (test=-0.548) total time=   0.0s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=32, n_estimators=50; f1: (test=0.736) neg_log_loss: (test=-0.532) total time=   0.0s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=32, n_estimators=100; f1: (test=0.713) neg_log_loss: (test=-0.549) total time=   0.1s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=32, n_estimators=100; f1: (test=0.697) neg_log_loss: (test=-0.555) total time=   0.1s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=32, n_estimators=100; f1: (test=0.722) neg_log_loss: (test=-0.553) total time=   0.1s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=32, n_estimators=100; f1: (test=0.715) neg_log_loss: (test=-0.551) total time=   0.1s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=32, n_estimators=100; f1: (test=0.737) neg_log_loss: (test=-0.535) total time=   0.1s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=32, n_estimators=200; f1: (test=0.724) neg_log_loss: (test=-0.547) total time=   0.3s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=32, n_estimators=200; f1: (test=0.698) neg_log_loss: (test=-0.553) total time=   0.3s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=32, n_estimators=200; f1: (test=0.723) neg_log_loss: (test=-0.551) total time=   0.3s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=32, n_estimators=200; f1: (test=0.724) neg_log_loss: (test=-0.548) total time=   0.3s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=32, n_estimators=200; f1: (test=0.739) neg_log_loss: (test=-0.532) total time=   0.3s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=32, n_estimators=250; f1: (test=0.723) neg_log_loss: (test=-0.546) total time=   0.4s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=32, n_estimators=250; f1: (test=0.698) neg_log_loss: (test=-0.553) total time=   0.4s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=32, n_estimators=250; f1: (test=0.723) neg_log_loss: (test=-0.551) total time=   0.4s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=32, n_estimators=250; f1: (test=0.724) neg_log_loss: (test=-0.549) total time=   0.4s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=32, n_estimators=250; f1: (test=0.740) neg_log_loss: (test=-0.532) total time=   0.4s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=2, n_estimators=25; f1: (test=0.771) neg_log_loss: (test=-0.486) total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=2, n_estimators=25; f1: (test=0.742) neg_log_loss: (test=-0.494) total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=2, n_estimators=25; f1: (test=0.755) neg_log_loss: (test=-0.493) total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=2, n_estimators=25; f1: (test=0.763) neg_log_loss: (test=-0.492) total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=2, n_estimators=25; f1: (test=0.785) neg_log_loss: (test=-0.464) total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=2, n_estimators=50; f1: (test=0.764) neg_log_loss: (test=-0.486) total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=2, n_estimators=50; f1: (test=0.757) neg_log_loss: (test=-0.493) total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=2, n_estimators=50; f1: (test=0.763) neg_log_loss: (test=-0.492) total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=2, n_estimators=50; f1: (test=0.761) neg_log_loss: (test=-0.491) total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=2, n_estimators=50; f1: (test=0.784) neg_log_loss: (test=-0.467) total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=2, n_estimators=100; f1: (test=0.760) neg_log_loss: (test=-0.487) total time=   0.2s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=2, n_estimators=100; f1: (test=0.755) neg_log_loss: (test=-0.492) total time=   0.2s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=2, n_estimators=100; f1: (test=0.770) neg_log_loss: (test=-0.490) total time=   0.2s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=2, n_estimators=100; f1: (test=0.772) neg_log_loss: (test=-0.490) total time=   0.2s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=2, n_estimators=100; f1: (test=0.784) neg_log_loss: (test=-0.466) total time=   0.2s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=2, n_estimators=200; f1: (test=0.767) neg_log_loss: (test=-0.486) total time=   0.4s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=2, n_estimators=200; f1: (test=0.757) neg_log_loss: (test=-0.490) total time=   0.4s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=2, n_estimators=200; f1: (test=0.769) neg_log_loss: (test=-0.490) total time=   0.5s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=2, n_estimators=200; f1: (test=0.777) neg_log_loss: (test=-0.489) total time=   0.4s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=2, n_estimators=200; f1: (test=0.784) neg_log_loss: (test=-0.465) total time=   0.4s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=2, n_estimators=250; f1: (test=0.765) neg_log_loss: (test=-0.486) total time=   0.6s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=2, n_estimators=250; f1: (test=0.760) neg_log_loss: (test=-0.490) total time=   0.6s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=2, n_estimators=250; f1: (test=0.770) neg_log_loss: (test=-0.490) total time=   0.6s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=2, n_estimators=250; f1: (test=0.778) neg_log_loss: (test=-0.490) total time=   0.6s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=2, n_estimators=250; f1: (test=0.786) neg_log_loss: (test=-0.466) total time=   0.6s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=4, n_estimators=25; f1: (test=0.771) neg_log_loss: (test=-0.486) total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=4, n_estimators=25; f1: (test=0.742) neg_log_loss: (test=-0.494) total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=4, n_estimators=25; f1: (test=0.755) neg_log_loss: (test=-0.494) total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=4, n_estimators=25; f1: (test=0.763) neg_log_loss: (test=-0.492) total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=4, n_estimators=25; f1: (test=0.794) neg_log_loss: (test=-0.464) total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=4, n_estimators=50; f1: (test=0.764) neg_log_loss: (test=-0.486) total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=4, n_estimators=50; f1: (test=0.757) neg_log_loss: (test=-0.493) total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=4, n_estimators=50; f1: (test=0.763) neg_log_loss: (test=-0.492) total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=4, n_estimators=50; f1: (test=0.761) neg_log_loss: (test=-0.491) total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=4, n_estimators=50; f1: (test=0.788) neg_log_loss: (test=-0.467) total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=4, n_estimators=100; f1: (test=0.760) neg_log_loss: (test=-0.487) total time=   0.2s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=4, n_estimators=100; f1: (test=0.755) neg_log_loss: (test=-0.492) total time=   0.2s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=4, n_estimators=100; f1: (test=0.770) neg_log_loss: (test=-0.490) total time=   0.2s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=4, n_estimators=100; f1: (test=0.772) neg_log_loss: (test=-0.490) total time=   0.2s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=4, n_estimators=100; f1: (test=0.785) neg_log_loss: (test=-0.466) total time=   0.2s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=4, n_estimators=200; f1: (test=0.767) neg_log_loss: (test=-0.486) total time=   0.4s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=4, n_estimators=200; f1: (test=0.757) neg_log_loss: (test=-0.490) total time=   0.4s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=4, n_estimators=200; f1: (test=0.769) neg_log_loss: (test=-0.490) total time=   0.4s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=4, n_estimators=200; f1: (test=0.777) neg_log_loss: (test=-0.489) total time=   0.4s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=4, n_estimators=200; f1: (test=0.785) neg_log_loss: (test=-0.465) total time=   0.4s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=4, n_estimators=250; f1: (test=0.765) neg_log_loss: (test=-0.486) total time=   0.6s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=4, n_estimators=250; f1: (test=0.756) neg_log_loss: (test=-0.490) total time=   0.6s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=4, n_estimators=250; f1: (test=0.770) neg_log_loss: (test=-0.490) total time=   0.6s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=4, n_estimators=250; f1: (test=0.778) neg_log_loss: (test=-0.490) total time=   0.6s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=4, n_estimators=250; f1: (test=0.786) neg_log_loss: (test=-0.466) total time=   0.6s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=8, n_estimators=25; f1: (test=0.774) neg_log_loss: (test=-0.485) total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=8, n_estimators=25; f1: (test=0.745) neg_log_loss: (test=-0.493) total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=8, n_estimators=25; f1: (test=0.754) neg_log_loss: (test=-0.494) total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=8, n_estimators=25; f1: (test=0.762) neg_log_loss: (test=-0.492) total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=8, n_estimators=25; f1: (test=0.794) neg_log_loss: (test=-0.464) total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=8, n_estimators=50; f1: (test=0.766) neg_log_loss: (test=-0.486) total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=8, n_estimators=50; f1: (test=0.758) neg_log_loss: (test=-0.492) total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=8, n_estimators=50; f1: (test=0.763) neg_log_loss: (test=-0.492) total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=8, n_estimators=50; f1: (test=0.761) neg_log_loss: (test=-0.491) total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=8, n_estimators=50; f1: (test=0.788) neg_log_loss: (test=-0.467) total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=8, n_estimators=100; f1: (test=0.760) neg_log_loss: (test=-0.486) total time=   0.2s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=8, n_estimators=100; f1: (test=0.756) neg_log_loss: (test=-0.491) total time=   0.2s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=8, n_estimators=100; f1: (test=0.770) neg_log_loss: (test=-0.490) total time=   0.2s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=8, n_estimators=100; f1: (test=0.772) neg_log_loss: (test=-0.490) total time=   0.2s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=8, n_estimators=100; f1: (test=0.785) neg_log_loss: (test=-0.466) total time=   0.2s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=8, n_estimators=200; f1: (test=0.767) neg_log_loss: (test=-0.486) total time=   0.4s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=8, n_estimators=200; f1: (test=0.758) neg_log_loss: (test=-0.490) total time=   0.4s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=8, n_estimators=200; f1: (test=0.770) neg_log_loss: (test=-0.490) total time=   0.4s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=8, n_estimators=200; f1: (test=0.777) neg_log_loss: (test=-0.489) total time=   0.4s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=8, n_estimators=200; f1: (test=0.786) neg_log_loss: (test=-0.465) total time=   0.4s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=8, n_estimators=250; f1: (test=0.766) neg_log_loss: (test=-0.486) total time=   0.6s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=8, n_estimators=250; f1: (test=0.756) neg_log_loss: (test=-0.490) total time=   0.6s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=8, n_estimators=250; f1: (test=0.769) neg_log_loss: (test=-0.490) total time=   0.6s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=8, n_estimators=250; f1: (test=0.778) neg_log_loss: (test=-0.490) total time=   0.6s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=8, n_estimators=250; f1: (test=0.786) neg_log_loss: (test=-0.466) total time=   0.6s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=16, n_estimators=25; f1: (test=0.774) neg_log_loss: (test=-0.484) total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=16, n_estimators=25; f1: (test=0.745) neg_log_loss: (test=-0.493) total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=16, n_estimators=25; f1: (test=0.755) neg_log_loss: (test=-0.493) total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=16, n_estimators=25; f1: (test=0.762) neg_log_loss: (test=-0.492) total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=16, n_estimators=25; f1: (test=0.793) neg_log_loss: (test=-0.464) total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=16, n_estimators=50; f1: (test=0.767) neg_log_loss: (test=-0.486) total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=16, n_estimators=50; f1: (test=0.757) neg_log_loss: (test=-0.492) total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=16, n_estimators=50; f1: (test=0.765) neg_log_loss: (test=-0.492) total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=16, n_estimators=50; f1: (test=0.761) neg_log_loss: (test=-0.491) total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=16, n_estimators=50; f1: (test=0.787) neg_log_loss: (test=-0.467) total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=16, n_estimators=100; f1: (test=0.760) neg_log_loss: (test=-0.486) total time=   0.2s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=16, n_estimators=100; f1: (test=0.756) neg_log_loss: (test=-0.491) total time=   0.2s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=16, n_estimators=100; f1: (test=0.769) neg_log_loss: (test=-0.490) total time=   0.2s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=16, n_estimators=100; f1: (test=0.772) neg_log_loss: (test=-0.490) total time=   0.2s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=16, n_estimators=100; f1: (test=0.785) neg_log_loss: (test=-0.466) total time=   0.2s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=16, n_estimators=200; f1: (test=0.767) neg_log_loss: (test=-0.486) total time=   0.4s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=16, n_estimators=200; f1: (test=0.758) neg_log_loss: (test=-0.490) total time=   0.4s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=16, n_estimators=200; f1: (test=0.771) neg_log_loss: (test=-0.490) total time=   0.5s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=16, n_estimators=200; f1: (test=0.778) neg_log_loss: (test=-0.489) total time=   0.4s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=16, n_estimators=200; f1: (test=0.784) neg_log_loss: (test=-0.465) total time=   0.5s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=16, n_estimators=250; f1: (test=0.765) neg_log_loss: (test=-0.486) total time=   0.6s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=16, n_estimators=250; f1: (test=0.756) neg_log_loss: (test=-0.490) total time=   0.6s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=16, n_estimators=250; f1: (test=0.768) neg_log_loss: (test=-0.490) total time=   0.6s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=16, n_estimators=250; f1: (test=0.778) neg_log_loss: (test=-0.490) total time=   0.6s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=16, n_estimators=250; f1: (test=0.787) neg_log_loss: (test=-0.466) total time=   0.6s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=32, n_estimators=25; f1: (test=0.775) neg_log_loss: (test=-0.484) total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=32, n_estimators=25; f1: (test=0.744) neg_log_loss: (test=-0.493) total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=32, n_estimators=25; f1: (test=0.755) neg_log_loss: (test=-0.493) total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=32, n_estimators=25; f1: (test=0.768) neg_log_loss: (test=-0.492) total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=32, n_estimators=25; f1: (test=0.787) neg_log_loss: (test=-0.464) total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=32, n_estimators=50; f1: (test=0.764) neg_log_loss: (test=-0.486) total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=32, n_estimators=50; f1: (test=0.757) neg_log_loss: (test=-0.492) total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=32, n_estimators=50; f1: (test=0.764) neg_log_loss: (test=-0.492) total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=32, n_estimators=50; f1: (test=0.762) neg_log_loss: (test=-0.491) total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=32, n_estimators=50; f1: (test=0.784) neg_log_loss: (test=-0.466) total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=32, n_estimators=100; f1: (test=0.760) neg_log_loss: (test=-0.486) total time=   0.2s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=32, n_estimators=100; f1: (test=0.757) neg_log_loss: (test=-0.491) total time=   0.2s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=32, n_estimators=100; f1: (test=0.765) neg_log_loss: (test=-0.490) total time=   0.2s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=32, n_estimators=100; f1: (test=0.769) neg_log_loss: (test=-0.490) total time=   0.2s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=32, n_estimators=100; f1: (test=0.784) neg_log_loss: (test=-0.466) total time=   0.2s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=32, n_estimators=200; f1: (test=0.768) neg_log_loss: (test=-0.486) total time=   0.4s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=32, n_estimators=200; f1: (test=0.757) neg_log_loss: (test=-0.490) total time=   0.4s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=32, n_estimators=200; f1: (test=0.768) neg_log_loss: (test=-0.490) total time=   0.4s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=32, n_estimators=200; f1: (test=0.777) neg_log_loss: (test=-0.489) total time=   0.5s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=32, n_estimators=200; f1: (test=0.785) neg_log_loss: (test=-0.465) total time=   0.4s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=32, n_estimators=250; f1: (test=0.765) neg_log_loss: (test=-0.486) total time=   0.6s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=32, n_estimators=250; f1: (test=0.755) neg_log_loss: (test=-0.490) total time=   0.5s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=32, n_estimators=250; f1: (test=0.769) neg_log_loss: (test=-0.490) total time=   0.6s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=32, n_estimators=250; f1: (test=0.778) neg_log_loss: (test=-0.490) total time=   0.6s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=32, n_estimators=250; f1: (test=0.787) neg_log_loss: (test=-0.465) total time=   0.6s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=2, n_estimators=25; f1: (test=0.806) neg_log_loss: (test=-0.442) total time=   0.0s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=2, n_estimators=25; f1: (test=0.798) neg_log_loss: (test=-0.440) total time=   0.0s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=2, n_estimators=25; f1: (test=0.794) neg_log_loss: (test=-0.453) total time=   0.0s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=2, n_estimators=25; f1: (test=0.801) neg_log_loss: (test=-0.447) total time=   0.0s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=2, n_estimators=25; f1: (test=0.813) neg_log_loss: (test=-0.419) total time=   0.0s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=2, n_estimators=50; f1: (test=0.810) neg_log_loss: (test=-0.441) total time=   0.1s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=2, n_estimators=50; f1: (test=0.803) neg_log_loss: (test=-0.439) total time=   0.1s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=2, n_estimators=50; f1: (test=0.799) neg_log_loss: (test=-0.451) total time=   0.1s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=2, n_estimators=50; f1: (test=0.806) neg_log_loss: (test=-0.448) total time=   0.1s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=2, n_estimators=50; f1: (test=0.813) neg_log_loss: (test=-0.419) total time=   0.1s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=2, n_estimators=100; f1: (test=0.809) neg_log_loss: (test=-0.441) total time=   0.3s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=2, n_estimators=100; f1: (test=0.804) neg_log_loss: (test=-0.441) total time=   0.3s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=2, n_estimators=100; f1: (test=0.799) neg_log_loss: (test=-0.450) total time=   0.3s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=2, n_estimators=100; f1: (test=0.803) neg_log_loss: (test=-0.446) total time=   0.3s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=2, n_estimators=100; f1: (test=0.809) neg_log_loss: (test=-0.420) total time=   0.3s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=2, n_estimators=200; f1: (test=0.809) neg_log_loss: (test=-0.441) total time=   0.6s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=2, n_estimators=200; f1: (test=0.804) neg_log_loss: (test=-0.440) total time=   0.6s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=2, n_estimators=200; f1: (test=0.798) neg_log_loss: (test=-0.449) total time=   0.6s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=2, n_estimators=200; f1: (test=0.808) neg_log_loss: (test=-0.446) total time=   0.6s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=2, n_estimators=200; f1: (test=0.807) neg_log_loss: (test=-0.420) total time=   0.7s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=2, n_estimators=250; f1: (test=0.809) neg_log_loss: (test=-0.441) total time=   0.9s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=2, n_estimators=250; f1: (test=0.805) neg_log_loss: (test=-0.439) total time=   0.8s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=2, n_estimators=250; f1: (test=0.799) neg_log_loss: (test=-0.449) total time=   0.8s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=2, n_estimators=250; f1: (test=0.808) neg_log_loss: (test=-0.446) total time=   0.8s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=2, n_estimators=250; f1: (test=0.806) neg_log_loss: (test=-0.420) total time=   0.8s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=4, n_estimators=25; f1: (test=0.796) neg_log_loss: (test=-0.446) total time=   0.0s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=4, n_estimators=25; f1: (test=0.803) neg_log_loss: (test=-0.442) total time=   0.0s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=4, n_estimators=25; f1: (test=0.795) neg_log_loss: (test=-0.453) total time=   0.0s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=4, n_estimators=25; f1: (test=0.798) neg_log_loss: (test=-0.450) total time=   0.0s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=4, n_estimators=25; f1: (test=0.814) neg_log_loss: (test=-0.418) total time=   0.0s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=4, n_estimators=50; f1: (test=0.804) neg_log_loss: (test=-0.444) total time=   0.1s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=4, n_estimators=50; f1: (test=0.806) neg_log_loss: (test=-0.441) total time=   0.1s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=4, n_estimators=50; f1: (test=0.801) neg_log_loss: (test=-0.450) total time=   0.1s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=4, n_estimators=50; f1: (test=0.803) neg_log_loss: (test=-0.449) total time=   0.1s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=4, n_estimators=50; f1: (test=0.812) neg_log_loss: (test=-0.418) total time=   0.1s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=4, n_estimators=100; f1: (test=0.808) neg_log_loss: (test=-0.442) total time=   0.3s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=4, n_estimators=100; f1: (test=0.804) neg_log_loss: (test=-0.440) total time=   0.3s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=4, n_estimators=100; f1: (test=0.801) neg_log_loss: (test=-0.448) total time=   0.3s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=4, n_estimators=100; f1: (test=0.805) neg_log_loss: (test=-0.448) total time=   0.3s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=4, n_estimators=100; f1: (test=0.810) neg_log_loss: (test=-0.418) total time=   0.3s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=4, n_estimators=200; f1: (test=0.808) neg_log_loss: (test=-0.441) total time=   0.6s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=4, n_estimators=200; f1: (test=0.804) neg_log_loss: (test=-0.439) total time=   0.6s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=4, n_estimators=200; f1: (test=0.800) neg_log_loss: (test=-0.448) total time=   0.6s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=4, n_estimators=200; f1: (test=0.809) neg_log_loss: (test=-0.447) total time=   0.6s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=4, n_estimators=200; f1: (test=0.809) neg_log_loss: (test=-0.418) total time=   0.6s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=4, n_estimators=250; f1: (test=0.809) neg_log_loss: (test=-0.441) total time=   0.8s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=4, n_estimators=250; f1: (test=0.804) neg_log_loss: (test=-0.439) total time=   0.8s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=4, n_estimators=250; f1: (test=0.800) neg_log_loss: (test=-0.448) total time=   0.8s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=4, n_estimators=250; f1: (test=0.805) neg_log_loss: (test=-0.447) total time=   0.8s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=4, n_estimators=250; f1: (test=0.806) neg_log_loss: (test=-0.419) total time=   0.8s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=8, n_estimators=25; f1: (test=0.803) neg_log_loss: (test=-0.444) total time=   0.0s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=8, n_estimators=25; f1: (test=0.805) neg_log_loss: (test=-0.441) total time=   0.0s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=8, n_estimators=25; f1: (test=0.799) neg_log_loss: (test=-0.449) total time=   0.0s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=8, n_estimators=25; f1: (test=0.799) neg_log_loss: (test=-0.451) total time=   0.0s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=8, n_estimators=25; f1: (test=0.811) neg_log_loss: (test=-0.422) total time=   0.0s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=8, n_estimators=50; f1: (test=0.805) neg_log_loss: (test=-0.442) total time=   0.1s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=8, n_estimators=50; f1: (test=0.805) neg_log_loss: (test=-0.440) total time=   0.1s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=8, n_estimators=50; f1: (test=0.802) neg_log_loss: (test=-0.447) total time=   0.1s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=8, n_estimators=50; f1: (test=0.803) neg_log_loss: (test=-0.448) total time=   0.1s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=8, n_estimators=50; f1: (test=0.814) neg_log_loss: (test=-0.419) total time=   0.1s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=8, n_estimators=100; f1: (test=0.805) neg_log_loss: (test=-0.441) total time=   0.3s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=8, n_estimators=100; f1: (test=0.805) neg_log_loss: (test=-0.441) total time=   0.3s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=8, n_estimators=100; f1: (test=0.800) neg_log_loss: (test=-0.447) total time=   0.3s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=8, n_estimators=100; f1: (test=0.805) neg_log_loss: (test=-0.447) total time=   0.3s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=8, n_estimators=100; f1: (test=0.811) neg_log_loss: (test=-0.419) total time=   0.3s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=8, n_estimators=200; f1: (test=0.808) neg_log_loss: (test=-0.441) total time=   0.6s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=8, n_estimators=200; f1: (test=0.805) neg_log_loss: (test=-0.440) total time=   0.6s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=8, n_estimators=200; f1: (test=0.796) neg_log_loss: (test=-0.448) total time=   0.6s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=8, n_estimators=200; f1: (test=0.806) neg_log_loss: (test=-0.447) total time=   0.6s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=8, n_estimators=200; f1: (test=0.813) neg_log_loss: (test=-0.419) total time=   0.6s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=8, n_estimators=250; f1: (test=0.807) neg_log_loss: (test=-0.441) total time=   0.8s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=8, n_estimators=250; f1: (test=0.806) neg_log_loss: (test=-0.440) total time=   0.8s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=8, n_estimators=250; f1: (test=0.799) neg_log_loss: (test=-0.448) total time=   0.8s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=8, n_estimators=250; f1: (test=0.805) neg_log_loss: (test=-0.447) total time=   0.8s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=8, n_estimators=250; f1: (test=0.813) neg_log_loss: (test=-0.419) total time=   0.8s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=16, n_estimators=25; f1: (test=0.805) neg_log_loss: (test=-0.445) total time=   0.0s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=16, n_estimators=25; f1: (test=0.806) neg_log_loss: (test=-0.440) total time=   0.0s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=16, n_estimators=25; f1: (test=0.800) neg_log_loss: (test=-0.450) total time=   0.0s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=16, n_estimators=25; f1: (test=0.791) neg_log_loss: (test=-0.454) total time=   0.0s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=16, n_estimators=25; f1: (test=0.813) neg_log_loss: (test=-0.423) total time=   0.0s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=16, n_estimators=50; f1: (test=0.810) neg_log_loss: (test=-0.442) total time=   0.1s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=16, n_estimators=50; f1: (test=0.807) neg_log_loss: (test=-0.439) total time=   0.1s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=16, n_estimators=50; f1: (test=0.800) neg_log_loss: (test=-0.447) total time=   0.1s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=16, n_estimators=50; f1: (test=0.802) neg_log_loss: (test=-0.450) total time=   0.1s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=16, n_estimators=50; f1: (test=0.808) neg_log_loss: (test=-0.421) total time=   0.1s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=16, n_estimators=100; f1: (test=0.807) neg_log_loss: (test=-0.442) total time=   0.3s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=16, n_estimators=100; f1: (test=0.806) neg_log_loss: (test=-0.441) total time=   0.3s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=16, n_estimators=100; f1: (test=0.802) neg_log_loss: (test=-0.448) total time=   0.3s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=16, n_estimators=100; f1: (test=0.797) neg_log_loss: (test=-0.449) total time=   0.3s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=16, n_estimators=100; f1: (test=0.810) neg_log_loss: (test=-0.421) total time=   0.3s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=16, n_estimators=200; f1: (test=0.803) neg_log_loss: (test=-0.441) total time=   0.6s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=16, n_estimators=200; f1: (test=0.800) neg_log_loss: (test=-0.441) total time=   0.6s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=16, n_estimators=200; f1: (test=0.802) neg_log_loss: (test=-0.448) total time=   0.6s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=16, n_estimators=200; f1: (test=0.805) neg_log_loss: (test=-0.448) total time=   0.6s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=16, n_estimators=200; f1: (test=0.814) neg_log_loss: (test=-0.421) total time=   0.6s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=16, n_estimators=250; f1: (test=0.804) neg_log_loss: (test=-0.441) total time=   0.8s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=16, n_estimators=250; f1: (test=0.801) neg_log_loss: (test=-0.441) total time=   0.8s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=16, n_estimators=250; f1: (test=0.801) neg_log_loss: (test=-0.448) total time=   0.8s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=16, n_estimators=250; f1: (test=0.806) neg_log_loss: (test=-0.448) total time=   0.8s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=16, n_estimators=250; f1: (test=0.808) neg_log_loss: (test=-0.421) total time=   0.8s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=32, n_estimators=25; f1: (test=0.809) neg_log_loss: (test=-0.443) total time=   0.0s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=32, n_estimators=25; f1: (test=0.804) neg_log_loss: (test=-0.445) total time=   0.0s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=32, n_estimators=25; f1: (test=0.799) neg_log_loss: (test=-0.451) total time=   0.0s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=32, n_estimators=25; f1: (test=0.794) neg_log_loss: (test=-0.452) total time=   0.0s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=32, n_estimators=25; f1: (test=0.813) neg_log_loss: (test=-0.421) total time=   0.0s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=32, n_estimators=50; f1: (test=0.812) neg_log_loss: (test=-0.443) total time=   0.1s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=32, n_estimators=50; f1: (test=0.808) neg_log_loss: (test=-0.444) total time=   0.1s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=32, n_estimators=50; f1: (test=0.799) neg_log_loss: (test=-0.450) total time=   0.1s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=32, n_estimators=50; f1: (test=0.803) neg_log_loss: (test=-0.450) total time=   0.1s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=32, n_estimators=50; f1: (test=0.812) neg_log_loss: (test=-0.421) total time=   0.1s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=32, n_estimators=100; f1: (test=0.807) neg_log_loss: (test=-0.443) total time=   0.3s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=32, n_estimators=100; f1: (test=0.806) neg_log_loss: (test=-0.442) total time=   0.3s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=32, n_estimators=100; f1: (test=0.799) neg_log_loss: (test=-0.449) total time=   0.3s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=32, n_estimators=100; f1: (test=0.806) neg_log_loss: (test=-0.450) total time=   0.3s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=32, n_estimators=100; f1: (test=0.812) neg_log_loss: (test=-0.421) total time=   0.3s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=32, n_estimators=200; f1: (test=0.803) neg_log_loss: (test=-0.442) total time=   0.6s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=32, n_estimators=200; f1: (test=0.803) neg_log_loss: (test=-0.442) total time=   0.6s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=32, n_estimators=200; f1: (test=0.796) neg_log_loss: (test=-0.449) total time=   0.6s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=32, n_estimators=200; f1: (test=0.806) neg_log_loss: (test=-0.450) total time=   0.6s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=32, n_estimators=200; f1: (test=0.808) neg_log_loss: (test=-0.420) total time=   0.6s\n",
      "[CV 1/5] END max_depth=8, min_samples_split=32, n_estimators=250; f1: (test=0.806) neg_log_loss: (test=-0.442) total time=   0.8s\n",
      "[CV 2/5] END max_depth=8, min_samples_split=32, n_estimators=250; f1: (test=0.803) neg_log_loss: (test=-0.442) total time=   0.8s\n",
      "[CV 3/5] END max_depth=8, min_samples_split=32, n_estimators=250; f1: (test=0.799) neg_log_loss: (test=-0.449) total time=   0.8s\n",
      "[CV 4/5] END max_depth=8, min_samples_split=32, n_estimators=250; f1: (test=0.805) neg_log_loss: (test=-0.450) total time=   0.8s\n",
      "[CV 5/5] END max_depth=8, min_samples_split=32, n_estimators=250; f1: (test=0.809) neg_log_loss: (test=-0.420) total time=   0.8s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=2, n_estimators=25; f1: (test=0.787) neg_log_loss: (test=-0.553) total time=   0.0s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=2, n_estimators=25; f1: (test=0.786) neg_log_loss: (test=-0.518) total time=   0.0s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=2, n_estimators=25; f1: (test=0.785) neg_log_loss: (test=-0.670) total time=   0.0s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=2, n_estimators=25; f1: (test=0.799) neg_log_loss: (test=-0.535) total time=   0.0s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=2, n_estimators=25; f1: (test=0.789) neg_log_loss: (test=-0.508) total time=   0.0s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=2, n_estimators=50; f1: (test=0.789) neg_log_loss: (test=-0.483) total time=   0.2s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=2, n_estimators=50; f1: (test=0.794) neg_log_loss: (test=-0.487) total time=   0.2s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=2, n_estimators=50; f1: (test=0.782) neg_log_loss: (test=-0.536) total time=   0.1s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=2, n_estimators=50; f1: (test=0.798) neg_log_loss: (test=-0.483) total time=   0.2s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=2, n_estimators=50; f1: (test=0.792) neg_log_loss: (test=-0.459) total time=   0.1s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=2, n_estimators=100; f1: (test=0.793) neg_log_loss: (test=-0.476) total time=   0.4s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=2, n_estimators=100; f1: (test=0.799) neg_log_loss: (test=-0.486) total time=   0.4s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=2, n_estimators=100; f1: (test=0.791) neg_log_loss: (test=-0.515) total time=   0.4s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=2, n_estimators=100; f1: (test=0.797) neg_log_loss: (test=-0.463) total time=   0.4s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=2, n_estimators=100; f1: (test=0.793) neg_log_loss: (test=-0.458) total time=   0.4s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=2, n_estimators=200; f1: (test=0.789) neg_log_loss: (test=-0.472) total time=   0.9s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=2, n_estimators=200; f1: (test=0.795) neg_log_loss: (test=-0.461) total time=   0.9s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=2, n_estimators=200; f1: (test=0.787) neg_log_loss: (test=-0.514) total time=   0.9s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=2, n_estimators=200; f1: (test=0.800) neg_log_loss: (test=-0.462) total time=   0.9s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=2, n_estimators=200; f1: (test=0.795) neg_log_loss: (test=-0.435) total time=   0.9s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=2, n_estimators=250; f1: (test=0.792) neg_log_loss: (test=-0.472) total time=   1.1s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=2, n_estimators=250; f1: (test=0.797) neg_log_loss: (test=-0.460) total time=   1.2s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=2, n_estimators=250; f1: (test=0.786) neg_log_loss: (test=-0.494) total time=   1.1s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=2, n_estimators=250; f1: (test=0.798) neg_log_loss: (test=-0.463) total time=   1.1s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=2, n_estimators=250; f1: (test=0.797) neg_log_loss: (test=-0.435) total time=   1.2s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=4, n_estimators=25; f1: (test=0.790) neg_log_loss: (test=-0.548) total time=   0.0s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=4, n_estimators=25; f1: (test=0.791) neg_log_loss: (test=-0.492) total time=   0.0s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=4, n_estimators=25; f1: (test=0.788) neg_log_loss: (test=-0.576) total time=   0.0s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=4, n_estimators=25; f1: (test=0.790) neg_log_loss: (test=-0.528) total time=   0.0s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=4, n_estimators=25; f1: (test=0.794) neg_log_loss: (test=-0.460) total time=   0.0s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=4, n_estimators=50; f1: (test=0.794) neg_log_loss: (test=-0.461) total time=   0.2s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=4, n_estimators=50; f1: (test=0.796) neg_log_loss: (test=-0.464) total time=   0.1s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=4, n_estimators=50; f1: (test=0.786) neg_log_loss: (test=-0.491) total time=   0.2s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=4, n_estimators=50; f1: (test=0.795) neg_log_loss: (test=-0.482) total time=   0.2s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=4, n_estimators=50; f1: (test=0.797) neg_log_loss: (test=-0.436) total time=   0.2s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=4, n_estimators=100; f1: (test=0.790) neg_log_loss: (test=-0.457) total time=   0.4s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=4, n_estimators=100; f1: (test=0.798) neg_log_loss: (test=-0.462) total time=   0.4s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=4, n_estimators=100; f1: (test=0.786) neg_log_loss: (test=-0.487) total time=   0.4s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=4, n_estimators=100; f1: (test=0.794) neg_log_loss: (test=-0.460) total time=   0.4s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=4, n_estimators=100; f1: (test=0.797) neg_log_loss: (test=-0.434) total time=   0.4s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=4, n_estimators=200; f1: (test=0.789) neg_log_loss: (test=-0.454) total time=   0.9s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=4, n_estimators=200; f1: (test=0.795) neg_log_loss: (test=-0.441) total time=   0.9s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=4, n_estimators=200; f1: (test=0.785) neg_log_loss: (test=-0.490) total time=   0.9s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=4, n_estimators=200; f1: (test=0.798) neg_log_loss: (test=-0.459) total time=   0.9s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=4, n_estimators=200; f1: (test=0.799) neg_log_loss: (test=-0.432) total time=   0.9s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=4, n_estimators=250; f1: (test=0.788) neg_log_loss: (test=-0.455) total time=   1.1s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=4, n_estimators=250; f1: (test=0.794) neg_log_loss: (test=-0.441) total time=   1.2s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=4, n_estimators=250; f1: (test=0.787) neg_log_loss: (test=-0.488) total time=   1.1s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=4, n_estimators=250; f1: (test=0.804) neg_log_loss: (test=-0.460) total time=   1.1s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=4, n_estimators=250; f1: (test=0.801) neg_log_loss: (test=-0.433) total time=   1.1s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=8, n_estimators=25; f1: (test=0.791) neg_log_loss: (test=-0.478) total time=   0.0s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=8, n_estimators=25; f1: (test=0.794) neg_log_loss: (test=-0.466) total time=   0.0s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=8, n_estimators=25; f1: (test=0.790) neg_log_loss: (test=-0.506) total time=   0.0s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=8, n_estimators=25; f1: (test=0.794) neg_log_loss: (test=-0.498) total time=   0.0s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=8, n_estimators=25; f1: (test=0.800) neg_log_loss: (test=-0.455) total time=   0.0s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=8, n_estimators=50; f1: (test=0.790) neg_log_loss: (test=-0.475) total time=   0.1s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=8, n_estimators=50; f1: (test=0.799) neg_log_loss: (test=-0.459) total time=   0.1s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=8, n_estimators=50; f1: (test=0.793) neg_log_loss: (test=-0.477) total time=   0.2s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=8, n_estimators=50; f1: (test=0.799) neg_log_loss: (test=-0.462) total time=   0.1s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=8, n_estimators=50; f1: (test=0.805) neg_log_loss: (test=-0.450) total time=   0.1s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=8, n_estimators=100; f1: (test=0.793) neg_log_loss: (test=-0.473) total time=   0.4s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=8, n_estimators=100; f1: (test=0.800) neg_log_loss: (test=-0.458) total time=   0.4s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=8, n_estimators=100; f1: (test=0.789) neg_log_loss: (test=-0.475) total time=   0.4s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=8, n_estimators=100; f1: (test=0.800) neg_log_loss: (test=-0.461) total time=   0.4s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=8, n_estimators=100; f1: (test=0.805) neg_log_loss: (test=-0.430) total time=   0.4s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=8, n_estimators=200; f1: (test=0.792) neg_log_loss: (test=-0.471) total time=   0.8s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=8, n_estimators=200; f1: (test=0.798) neg_log_loss: (test=-0.438) total time=   0.9s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=8, n_estimators=200; f1: (test=0.788) neg_log_loss: (test=-0.476) total time=   0.9s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=8, n_estimators=200; f1: (test=0.799) neg_log_loss: (test=-0.457) total time=   0.9s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=8, n_estimators=200; f1: (test=0.807) neg_log_loss: (test=-0.429) total time=   0.8s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=8, n_estimators=250; f1: (test=0.793) neg_log_loss: (test=-0.470) total time=   1.1s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=8, n_estimators=250; f1: (test=0.800) neg_log_loss: (test=-0.438) total time=   1.1s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=8, n_estimators=250; f1: (test=0.792) neg_log_loss: (test=-0.475) total time=   1.2s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=8, n_estimators=250; f1: (test=0.800) neg_log_loss: (test=-0.457) total time=   1.1s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=8, n_estimators=250; f1: (test=0.809) neg_log_loss: (test=-0.429) total time=   1.1s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=16, n_estimators=25; f1: (test=0.797) neg_log_loss: (test=-0.473) total time=   0.0s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=16, n_estimators=25; f1: (test=0.793) neg_log_loss: (test=-0.461) total time=   0.0s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=16, n_estimators=25; f1: (test=0.782) neg_log_loss: (test=-0.475) total time=   0.0s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=16, n_estimators=25; f1: (test=0.800) neg_log_loss: (test=-0.501) total time=   0.0s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=16, n_estimators=25; f1: (test=0.805) neg_log_loss: (test=-0.430) total time=   0.0s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=16, n_estimators=50; f1: (test=0.798) neg_log_loss: (test=-0.468) total time=   0.1s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=16, n_estimators=50; f1: (test=0.801) neg_log_loss: (test=-0.460) total time=   0.2s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=16, n_estimators=50; f1: (test=0.782) neg_log_loss: (test=-0.466) total time=   0.2s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=16, n_estimators=50; f1: (test=0.803) neg_log_loss: (test=-0.474) total time=   0.2s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=16, n_estimators=50; f1: (test=0.806) neg_log_loss: (test=-0.428) total time=   0.2s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=16, n_estimators=100; f1: (test=0.800) neg_log_loss: (test=-0.467) total time=   0.4s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=16, n_estimators=100; f1: (test=0.798) neg_log_loss: (test=-0.439) total time=   0.4s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=16, n_estimators=100; f1: (test=0.788) neg_log_loss: (test=-0.466) total time=   0.4s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=16, n_estimators=100; f1: (test=0.800) neg_log_loss: (test=-0.453) total time=   0.4s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=16, n_estimators=100; f1: (test=0.807) neg_log_loss: (test=-0.426) total time=   0.4s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=16, n_estimators=200; f1: (test=0.800) neg_log_loss: (test=-0.465) total time=   0.9s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=16, n_estimators=200; f1: (test=0.801) neg_log_loss: (test=-0.438) total time=   0.8s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=16, n_estimators=200; f1: (test=0.785) neg_log_loss: (test=-0.467) total time=   0.8s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=16, n_estimators=200; f1: (test=0.802) neg_log_loss: (test=-0.452) total time=   0.8s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=16, n_estimators=200; f1: (test=0.810) neg_log_loss: (test=-0.425) total time=   0.8s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=16, n_estimators=250; f1: (test=0.798) neg_log_loss: (test=-0.465) total time=   1.1s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=16, n_estimators=250; f1: (test=0.802) neg_log_loss: (test=-0.437) total time=   1.1s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=16, n_estimators=250; f1: (test=0.785) neg_log_loss: (test=-0.467) total time=   1.1s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=16, n_estimators=250; f1: (test=0.802) neg_log_loss: (test=-0.452) total time=   1.1s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=16, n_estimators=250; f1: (test=0.809) neg_log_loss: (test=-0.426) total time=   1.1s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=32, n_estimators=25; f1: (test=0.805) neg_log_loss: (test=-0.440) total time=   0.0s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=32, n_estimators=25; f1: (test=0.795) neg_log_loss: (test=-0.460) total time=   0.0s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=32, n_estimators=25; f1: (test=0.788) neg_log_loss: (test=-0.480) total time=   0.0s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=32, n_estimators=25; f1: (test=0.797) neg_log_loss: (test=-0.456) total time=   0.0s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=32, n_estimators=25; f1: (test=0.808) neg_log_loss: (test=-0.449) total time=   0.0s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=32, n_estimators=50; f1: (test=0.797) neg_log_loss: (test=-0.441) total time=   0.1s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=32, n_estimators=50; f1: (test=0.805) neg_log_loss: (test=-0.460) total time=   0.1s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=32, n_estimators=50; f1: (test=0.786) neg_log_loss: (test=-0.477) total time=   0.1s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=32, n_estimators=50; f1: (test=0.800) neg_log_loss: (test=-0.454) total time=   0.1s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=32, n_estimators=50; f1: (test=0.811) neg_log_loss: (test=-0.426) total time=   0.1s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=32, n_estimators=100; f1: (test=0.798) neg_log_loss: (test=-0.441) total time=   0.4s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=32, n_estimators=100; f1: (test=0.805) neg_log_loss: (test=-0.440) total time=   0.3s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=32, n_estimators=100; f1: (test=0.787) neg_log_loss: (test=-0.458) total time=   0.3s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=32, n_estimators=100; f1: (test=0.803) neg_log_loss: (test=-0.451) total time=   0.3s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=32, n_estimators=100; f1: (test=0.812) neg_log_loss: (test=-0.425) total time=   0.4s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=32, n_estimators=200; f1: (test=0.800) neg_log_loss: (test=-0.441) total time=   0.8s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=32, n_estimators=200; f1: (test=0.805) neg_log_loss: (test=-0.438) total time=   0.8s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=32, n_estimators=200; f1: (test=0.785) neg_log_loss: (test=-0.457) total time=   0.7s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=32, n_estimators=200; f1: (test=0.806) neg_log_loss: (test=-0.448) total time=   0.8s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=32, n_estimators=200; f1: (test=0.811) neg_log_loss: (test=-0.423) total time=   0.8s\n",
      "[CV 1/5] END max_depth=16, min_samples_split=32, n_estimators=250; f1: (test=0.803) neg_log_loss: (test=-0.441) total time=   1.0s\n",
      "[CV 2/5] END max_depth=16, min_samples_split=32, n_estimators=250; f1: (test=0.803) neg_log_loss: (test=-0.439) total time=   1.0s\n",
      "[CV 3/5] END max_depth=16, min_samples_split=32, n_estimators=250; f1: (test=0.787) neg_log_loss: (test=-0.457) total time=   1.0s\n",
      "[CV 4/5] END max_depth=16, min_samples_split=32, n_estimators=250; f1: (test=0.803) neg_log_loss: (test=-0.449) total time=   1.0s\n",
      "[CV 5/5] END max_depth=16, min_samples_split=32, n_estimators=250; f1: (test=0.810) neg_log_loss: (test=-0.423) total time=   1.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'max_depth': [2, 4, 8, 16],\n",
       "                         'min_samples_split': [2, 4, 8, 16, 32],\n",
       "                         'n_estimators': [25, 50, 100, 200, 250]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'f1'], verbose=4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_xgb = GridSearchCV(estimator=xgb_classfier,\n",
    "                                  param_grid=search_space[\"xgboost_classifier\"],\n",
    "                                  scoring=[\"neg_log_loss\", \"f1\"],\n",
    "                                  refit=\"neg_log_loss\",\n",
    "                                  cv=5, # k-fold cross validation\n",
    "                                  verbose=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=25; f1: (test=0.676) neg_log_loss: (test=-0.687) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=25; f1: (test=0.656) neg_log_loss: (test=-0.687) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=25; f1: (test=0.654) neg_log_loss: (test=-0.687) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=25; f1: (test=0.669) neg_log_loss: (test=-0.687) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=25; f1: (test=0.679) neg_log_loss: (test=-0.687) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=50; f1: (test=0.676) neg_log_loss: (test=-0.680) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=50; f1: (test=0.656) neg_log_loss: (test=-0.681) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=50; f1: (test=0.654) neg_log_loss: (test=-0.681) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=50; f1: (test=0.669) neg_log_loss: (test=-0.681) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=50; f1: (test=0.679) neg_log_loss: (test=-0.680) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=100; f1: (test=0.676) neg_log_loss: (test=-0.669) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=100; f1: (test=0.656) neg_log_loss: (test=-0.669) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=100; f1: (test=0.654) neg_log_loss: (test=-0.669) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=100; f1: (test=0.669) neg_log_loss: (test=-0.669) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=100; f1: (test=0.679) neg_log_loss: (test=-0.668) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=200; f1: (test=0.676) neg_log_loss: (test=-0.648) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=200; f1: (test=0.656) neg_log_loss: (test=-0.649) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=200; f1: (test=0.654) neg_log_loss: (test=-0.650) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=200; f1: (test=0.669) neg_log_loss: (test=-0.649) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=200; f1: (test=0.679) neg_log_loss: (test=-0.647) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=250; f1: (test=0.676) neg_log_loss: (test=-0.639) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=250; f1: (test=0.656) neg_log_loss: (test=-0.641) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=250; f1: (test=0.654) neg_log_loss: (test=-0.641) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=250; f1: (test=0.669) neg_log_loss: (test=-0.641) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=250; f1: (test=0.679) neg_log_loss: (test=-0.637) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=25; f1: (test=0.787) neg_log_loss: (test=-0.684) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=25; f1: (test=0.773) neg_log_loss: (test=-0.684) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=25; f1: (test=0.781) neg_log_loss: (test=-0.684) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=25; f1: (test=0.771) neg_log_loss: (test=-0.685) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=25; f1: (test=0.797) neg_log_loss: (test=-0.684) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=50; f1: (test=0.791) neg_log_loss: (test=-0.676) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=50; f1: (test=0.773) neg_log_loss: (test=-0.676) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=50; f1: (test=0.781) neg_log_loss: (test=-0.676) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=50; f1: (test=0.770) neg_log_loss: (test=-0.676) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=50; f1: (test=0.801) neg_log_loss: (test=-0.675) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=100; f1: (test=0.781) neg_log_loss: (test=-0.660) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=100; f1: (test=0.774) neg_log_loss: (test=-0.660) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=100; f1: (test=0.781) neg_log_loss: (test=-0.660) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=100; f1: (test=0.770) neg_log_loss: (test=-0.661) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=100; f1: (test=0.806) neg_log_loss: (test=-0.659) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=200; f1: (test=0.788) neg_log_loss: (test=-0.633) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=200; f1: (test=0.782) neg_log_loss: (test=-0.633) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=200; f1: (test=0.780) neg_log_loss: (test=-0.633) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=200; f1: (test=0.771) neg_log_loss: (test=-0.635) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=200; f1: (test=0.782) neg_log_loss: (test=-0.630) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=250; f1: (test=0.792) neg_log_loss: (test=-0.621) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=250; f1: (test=0.783) neg_log_loss: (test=-0.621) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=250; f1: (test=0.789) neg_log_loss: (test=-0.621) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=250; f1: (test=0.773) neg_log_loss: (test=-0.623) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=4, n_estimators=250; f1: (test=0.785) neg_log_loss: (test=-0.617) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=25; f1: (test=0.796) neg_log_loss: (test=-0.683) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=25; f1: (test=0.799) neg_log_loss: (test=-0.683) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=25; f1: (test=0.792) neg_log_loss: (test=-0.683) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=25; f1: (test=0.790) neg_log_loss: (test=-0.683) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=25; f1: (test=0.804) neg_log_loss: (test=-0.682) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=50; f1: (test=0.796) neg_log_loss: (test=-0.673) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=50; f1: (test=0.799) neg_log_loss: (test=-0.673) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=50; f1: (test=0.798) neg_log_loss: (test=-0.673) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=50; f1: (test=0.789) neg_log_loss: (test=-0.673) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=50; f1: (test=0.804) neg_log_loss: (test=-0.672) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=100; f1: (test=0.789) neg_log_loss: (test=-0.655) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=100; f1: (test=0.799) neg_log_loss: (test=-0.654) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=100; f1: (test=0.802) neg_log_loss: (test=-0.655) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=100; f1: (test=0.789) neg_log_loss: (test=-0.655) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=100; f1: (test=0.805) neg_log_loss: (test=-0.653) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=200; f1: (test=0.798) neg_log_loss: (test=-0.624) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=200; f1: (test=0.799) neg_log_loss: (test=-0.622) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=200; f1: (test=0.799) neg_log_loss: (test=-0.623) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=200; f1: (test=0.792) neg_log_loss: (test=-0.624) total time=   0.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=200; f1: (test=0.807) neg_log_loss: (test=-0.620) total time=   0.5s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=250; f1: (test=0.798) neg_log_loss: (test=-0.610) total time=   0.7s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=250; f1: (test=0.801) neg_log_loss: (test=-0.608) total time=   0.7s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=250; f1: (test=0.799) neg_log_loss: (test=-0.609) total time=   0.7s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=250; f1: (test=0.794) neg_log_loss: (test=-0.610) total time=   0.6s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=8, n_estimators=250; f1: (test=0.808) neg_log_loss: (test=-0.606) total time=   0.6s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=25; f1: (test=0.779) neg_log_loss: (test=-0.683) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=25; f1: (test=0.784) neg_log_loss: (test=-0.682) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=25; f1: (test=0.764) neg_log_loss: (test=-0.683) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=25; f1: (test=0.774) neg_log_loss: (test=-0.683) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=25; f1: (test=0.781) neg_log_loss: (test=-0.682) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=50; f1: (test=0.783) neg_log_loss: (test=-0.673) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=50; f1: (test=0.784) neg_log_loss: (test=-0.672) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=50; f1: (test=0.769) neg_log_loss: (test=-0.673) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=50; f1: (test=0.781) neg_log_loss: (test=-0.673) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=50; f1: (test=0.782) neg_log_loss: (test=-0.672) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=100; f1: (test=0.779) neg_log_loss: (test=-0.654) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=100; f1: (test=0.787) neg_log_loss: (test=-0.653) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=100; f1: (test=0.773) neg_log_loss: (test=-0.655) total time=   0.5s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=100; f1: (test=0.782) neg_log_loss: (test=-0.655) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=100; f1: (test=0.780) neg_log_loss: (test=-0.653) total time=   0.5s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=200; f1: (test=0.783) neg_log_loss: (test=-0.623) total time=   1.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=200; f1: (test=0.785) neg_log_loss: (test=-0.622) total time=   1.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=200; f1: (test=0.781) neg_log_loss: (test=-0.623) total time=   1.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=200; f1: (test=0.780) neg_log_loss: (test=-0.623) total time=   1.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=200; f1: (test=0.785) neg_log_loss: (test=-0.620) total time=   1.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=250; f1: (test=0.784) neg_log_loss: (test=-0.609) total time=   1.3s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=250; f1: (test=0.790) neg_log_loss: (test=-0.608) total time=   1.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=250; f1: (test=0.781) neg_log_loss: (test=-0.609) total time=   1.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=250; f1: (test=0.778) neg_log_loss: (test=-0.610) total time=   1.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=16, n_estimators=250; f1: (test=0.787) neg_log_loss: (test=-0.606) total time=   2.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=25; f1: (test=0.676) neg_log_loss: (test=-0.639) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=25; f1: (test=0.656) neg_log_loss: (test=-0.641) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=25; f1: (test=0.654) neg_log_loss: (test=-0.641) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=25; f1: (test=0.669) neg_log_loss: (test=-0.640) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=25; f1: (test=0.679) neg_log_loss: (test=-0.637) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=50; f1: (test=0.676) neg_log_loss: (test=-0.603) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=50; f1: (test=0.656) neg_log_loss: (test=-0.606) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=50; f1: (test=0.654) neg_log_loss: (test=-0.606) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=50; f1: (test=0.669) neg_log_loss: (test=-0.606) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=50; f1: (test=0.679) neg_log_loss: (test=-0.600) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=100; f1: (test=0.698) neg_log_loss: (test=-0.559) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=100; f1: (test=0.656) neg_log_loss: (test=-0.563) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=100; f1: (test=0.654) neg_log_loss: (test=-0.563) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=100; f1: (test=0.669) neg_log_loss: (test=-0.563) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=100; f1: (test=0.679) neg_log_loss: (test=-0.552) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=200; f1: (test=0.791) neg_log_loss: (test=-0.513) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=200; f1: (test=0.779) neg_log_loss: (test=-0.515) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=200; f1: (test=0.785) neg_log_loss: (test=-0.518) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=200; f1: (test=0.785) neg_log_loss: (test=-0.517) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=200; f1: (test=0.798) neg_log_loss: (test=-0.500) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=250; f1: (test=0.793) neg_log_loss: (test=-0.501) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=250; f1: (test=0.784) neg_log_loss: (test=-0.502) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=250; f1: (test=0.790) neg_log_loss: (test=-0.505) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=250; f1: (test=0.795) neg_log_loss: (test=-0.505) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=2, n_estimators=250; f1: (test=0.803) neg_log_loss: (test=-0.486) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=25; f1: (test=0.793) neg_log_loss: (test=-0.621) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=25; f1: (test=0.783) neg_log_loss: (test=-0.621) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=25; f1: (test=0.789) neg_log_loss: (test=-0.621) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=25; f1: (test=0.773) neg_log_loss: (test=-0.623) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=25; f1: (test=0.785) neg_log_loss: (test=-0.617) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=50; f1: (test=0.794) neg_log_loss: (test=-0.572) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=50; f1: (test=0.796) neg_log_loss: (test=-0.571) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=50; f1: (test=0.778) neg_log_loss: (test=-0.573) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=50; f1: (test=0.770) neg_log_loss: (test=-0.576) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=50; f1: (test=0.787) neg_log_loss: (test=-0.566) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=100; f1: (test=0.805) neg_log_loss: (test=-0.513) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=100; f1: (test=0.798) neg_log_loss: (test=-0.512) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=100; f1: (test=0.783) neg_log_loss: (test=-0.516) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=100; f1: (test=0.792) neg_log_loss: (test=-0.520) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=100; f1: (test=0.802) neg_log_loss: (test=-0.504) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=200; f1: (test=0.808) neg_log_loss: (test=-0.464) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=200; f1: (test=0.802) neg_log_loss: (test=-0.463) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=200; f1: (test=0.795) neg_log_loss: (test=-0.469) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=200; f1: (test=0.801) neg_log_loss: (test=-0.474) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=200; f1: (test=0.811) neg_log_loss: (test=-0.449) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=250; f1: (test=0.810) neg_log_loss: (test=-0.454) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=250; f1: (test=0.800) neg_log_loss: (test=-0.450) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=250; f1: (test=0.805) neg_log_loss: (test=-0.458) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=250; f1: (test=0.800) neg_log_loss: (test=-0.464) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=250; f1: (test=0.814) neg_log_loss: (test=-0.436) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=25; f1: (test=0.798) neg_log_loss: (test=-0.610) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=25; f1: (test=0.801) neg_log_loss: (test=-0.608) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=25; f1: (test=0.800) neg_log_loss: (test=-0.609) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=25; f1: (test=0.792) neg_log_loss: (test=-0.610) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=25; f1: (test=0.807) neg_log_loss: (test=-0.605) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=50; f1: (test=0.805) neg_log_loss: (test=-0.555) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=50; f1: (test=0.800) neg_log_loss: (test=-0.553) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=50; f1: (test=0.802) neg_log_loss: (test=-0.554) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=50; f1: (test=0.789) neg_log_loss: (test=-0.558) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=50; f1: (test=0.806) neg_log_loss: (test=-0.549) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=100; f1: (test=0.799) neg_log_loss: (test=-0.494) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=100; f1: (test=0.803) neg_log_loss: (test=-0.488) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=100; f1: (test=0.803) neg_log_loss: (test=-0.493) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=100; f1: (test=0.802) neg_log_loss: (test=-0.501) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=100; f1: (test=0.812) neg_log_loss: (test=-0.485) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=200; f1: (test=0.805) neg_log_loss: (test=-0.452) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=200; f1: (test=0.805) neg_log_loss: (test=-0.442) total time=   0.5s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=200; f1: (test=0.799) neg_log_loss: (test=-0.453) total time=   0.5s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=200; f1: (test=0.801) neg_log_loss: (test=-0.461) total time=   0.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=200; f1: (test=0.815) neg_log_loss: (test=-0.437) total time=   0.5s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=250; f1: (test=0.804) neg_log_loss: (test=-0.446) total time=   0.7s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=250; f1: (test=0.800) neg_log_loss: (test=-0.434) total time=   0.7s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=250; f1: (test=0.805) neg_log_loss: (test=-0.447) total time=   0.7s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=250; f1: (test=0.798) neg_log_loss: (test=-0.454) total time=   0.7s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=8, n_estimators=250; f1: (test=0.814) neg_log_loss: (test=-0.428) total time=   0.7s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=25; f1: (test=0.785) neg_log_loss: (test=-0.608) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=25; f1: (test=0.790) neg_log_loss: (test=-0.607) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=25; f1: (test=0.780) neg_log_loss: (test=-0.609) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=25; f1: (test=0.777) neg_log_loss: (test=-0.610) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=25; f1: (test=0.788) neg_log_loss: (test=-0.606) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=50; f1: (test=0.785) neg_log_loss: (test=-0.554) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=50; f1: (test=0.785) neg_log_loss: (test=-0.552) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=50; f1: (test=0.783) neg_log_loss: (test=-0.556) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=50; f1: (test=0.783) neg_log_loss: (test=-0.558) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=50; f1: (test=0.787) neg_log_loss: (test=-0.551) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=100; f1: (test=0.791) neg_log_loss: (test=-0.494) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=100; f1: (test=0.789) neg_log_loss: (test=-0.490) total time=   0.5s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=100; f1: (test=0.785) neg_log_loss: (test=-0.501) total time=   0.5s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=100; f1: (test=0.784) neg_log_loss: (test=-0.503) total time=   0.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=100; f1: (test=0.795) neg_log_loss: (test=-0.490) total time=   0.6s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=200; f1: (test=0.786) neg_log_loss: (test=-0.458) total time=   1.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=200; f1: (test=0.802) neg_log_loss: (test=-0.448) total time=   1.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=200; f1: (test=0.784) neg_log_loss: (test=-0.468) total time=   1.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=200; f1: (test=0.787) neg_log_loss: (test=-0.470) total time=   1.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=200; f1: (test=0.796) neg_log_loss: (test=-0.448) total time=   1.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=250; f1: (test=0.789) neg_log_loss: (test=-0.455) total time=   1.6s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=250; f1: (test=0.796) neg_log_loss: (test=-0.444) total time=   1.6s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=250; f1: (test=0.783) neg_log_loss: (test=-0.467) total time=   1.5s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=250; f1: (test=0.786) neg_log_loss: (test=-0.466) total time=   1.6s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=16, n_estimators=250; f1: (test=0.800) neg_log_loss: (test=-0.443) total time=   1.6s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=25; f1: (test=0.792) neg_log_loss: (test=-0.500) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=25; f1: (test=0.776) neg_log_loss: (test=-0.501) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=25; f1: (test=0.789) neg_log_loss: (test=-0.504) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=25; f1: (test=0.801) neg_log_loss: (test=-0.503) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=25; f1: (test=0.808) neg_log_loss: (test=-0.484) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=50; f1: (test=0.796) neg_log_loss: (test=-0.470) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=50; f1: (test=0.794) neg_log_loss: (test=-0.465) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=50; f1: (test=0.802) neg_log_loss: (test=-0.473) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=50; f1: (test=0.793) neg_log_loss: (test=-0.473) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=50; f1: (test=0.814) neg_log_loss: (test=-0.449) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=100; f1: (test=0.807) neg_log_loss: (test=-0.450) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=100; f1: (test=0.805) neg_log_loss: (test=-0.442) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=100; f1: (test=0.801) neg_log_loss: (test=-0.453) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=100; f1: (test=0.800) neg_log_loss: (test=-0.454) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=100; f1: (test=0.815) neg_log_loss: (test=-0.427) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=200; f1: (test=0.805) neg_log_loss: (test=-0.440) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=200; f1: (test=0.810) neg_log_loss: (test=-0.431) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=200; f1: (test=0.802) neg_log_loss: (test=-0.446) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=200; f1: (test=0.807) neg_log_loss: (test=-0.444) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=200; f1: (test=0.809) neg_log_loss: (test=-0.417) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=250; f1: (test=0.801) neg_log_loss: (test=-0.438) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=250; f1: (test=0.810) neg_log_loss: (test=-0.430) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=250; f1: (test=0.803) neg_log_loss: (test=-0.447) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=250; f1: (test=0.806) neg_log_loss: (test=-0.443) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=2, n_estimators=250; f1: (test=0.814) neg_log_loss: (test=-0.417) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=25; f1: (test=0.808) neg_log_loss: (test=-0.452) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=25; f1: (test=0.802) neg_log_loss: (test=-0.447) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=25; f1: (test=0.798) neg_log_loss: (test=-0.458) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=25; f1: (test=0.799) neg_log_loss: (test=-0.463) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=25; f1: (test=0.814) neg_log_loss: (test=-0.435) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=50; f1: (test=0.808) neg_log_loss: (test=-0.438) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=50; f1: (test=0.807) neg_log_loss: (test=-0.430) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=50; f1: (test=0.805) neg_log_loss: (test=-0.446) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=50; f1: (test=0.808) neg_log_loss: (test=-0.449) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=50; f1: (test=0.810) neg_log_loss: (test=-0.418) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=100; f1: (test=0.804) neg_log_loss: (test=-0.434) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=100; f1: (test=0.810) neg_log_loss: (test=-0.425) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=100; f1: (test=0.812) neg_log_loss: (test=-0.442) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=100; f1: (test=0.810) neg_log_loss: (test=-0.443) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=100; f1: (test=0.808) neg_log_loss: (test=-0.416) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=200; f1: (test=0.803) neg_log_loss: (test=-0.435) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=200; f1: (test=0.808) neg_log_loss: (test=-0.428) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=200; f1: (test=0.805) neg_log_loss: (test=-0.446) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=200; f1: (test=0.811) neg_log_loss: (test=-0.446) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=200; f1: (test=0.806) neg_log_loss: (test=-0.423) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=250; f1: (test=0.803) neg_log_loss: (test=-0.436) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=250; f1: (test=0.803) neg_log_loss: (test=-0.431) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=250; f1: (test=0.801) neg_log_loss: (test=-0.449) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=250; f1: (test=0.809) neg_log_loss: (test=-0.447) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=250; f1: (test=0.805) neg_log_loss: (test=-0.426) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=25; f1: (test=0.799) neg_log_loss: (test=-0.447) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=25; f1: (test=0.797) neg_log_loss: (test=-0.436) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=25; f1: (test=0.801) neg_log_loss: (test=-0.447) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=25; f1: (test=0.799) neg_log_loss: (test=-0.455) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=25; f1: (test=0.811) neg_log_loss: (test=-0.428) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=50; f1: (test=0.799) neg_log_loss: (test=-0.445) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=50; f1: (test=0.801) neg_log_loss: (test=-0.430) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=50; f1: (test=0.804) neg_log_loss: (test=-0.445) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=50; f1: (test=0.800) neg_log_loss: (test=-0.450) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=50; f1: (test=0.811) neg_log_loss: (test=-0.421) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=100; f1: (test=0.791) neg_log_loss: (test=-0.451) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=100; f1: (test=0.799) neg_log_loss: (test=-0.435) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=100; f1: (test=0.797) neg_log_loss: (test=-0.454) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=100; f1: (test=0.805) neg_log_loss: (test=-0.455) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=100; f1: (test=0.807) neg_log_loss: (test=-0.428) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=200; f1: (test=0.793) neg_log_loss: (test=-0.462) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=200; f1: (test=0.796) neg_log_loss: (test=-0.447) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=200; f1: (test=0.798) neg_log_loss: (test=-0.474) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=200; f1: (test=0.798) neg_log_loss: (test=-0.466) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=200; f1: (test=0.804) neg_log_loss: (test=-0.446) total time=   0.4s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=250; f1: (test=0.789) neg_log_loss: (test=-0.471) total time=   0.6s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=250; f1: (test=0.795) neg_log_loss: (test=-0.456) total time=   0.5s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=250; f1: (test=0.795) neg_log_loss: (test=-0.483) total time=   0.5s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=250; f1: (test=0.794) neg_log_loss: (test=-0.471) total time=   0.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=8, n_estimators=250; f1: (test=0.806) neg_log_loss: (test=-0.455) total time=   0.5s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=25; f1: (test=0.790) neg_log_loss: (test=-0.457) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=25; f1: (test=0.800) neg_log_loss: (test=-0.440) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=25; f1: (test=0.786) neg_log_loss: (test=-0.465) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=25; f1: (test=0.783) neg_log_loss: (test=-0.466) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=25; f1: (test=0.796) neg_log_loss: (test=-0.443) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=50; f1: (test=0.787) neg_log_loss: (test=-0.467) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=50; f1: (test=0.795) neg_log_loss: (test=-0.450) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=50; f1: (test=0.784) neg_log_loss: (test=-0.480) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=50; f1: (test=0.786) neg_log_loss: (test=-0.469) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=50; f1: (test=0.795) neg_log_loss: (test=-0.448) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=100; f1: (test=0.782) neg_log_loss: (test=-0.490) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=100; f1: (test=0.796) neg_log_loss: (test=-0.465) total time=   0.6s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=100; f1: (test=0.784) neg_log_loss: (test=-0.499) total time=   0.5s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=100; f1: (test=0.782) neg_log_loss: (test=-0.482) total time=   0.6s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=100; f1: (test=0.796) neg_log_loss: (test=-0.463) total time=   0.4s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=200; f1: (test=0.778) neg_log_loss: (test=-0.522) total time=   0.9s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=200; f1: (test=0.795) neg_log_loss: (test=-0.494) total time=   0.9s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=200; f1: (test=0.782) neg_log_loss: (test=-0.538) total time=   0.9s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=200; f1: (test=0.795) neg_log_loss: (test=-0.507) total time=   0.9s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=200; f1: (test=0.794) neg_log_loss: (test=-0.494) total time=   1.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=250; f1: (test=0.779) neg_log_loss: (test=-0.534) total time=   1.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=250; f1: (test=0.795) neg_log_loss: (test=-0.505) total time=   1.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=250; f1: (test=0.781) neg_log_loss: (test=-0.555) total time=   1.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=250; f1: (test=0.793) neg_log_loss: (test=-0.520) total time=   1.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=16, n_estimators=250; f1: (test=0.797) neg_log_loss: (test=-0.508) total time=   1.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=25; f1: (test=0.801) neg_log_loss: (test=-0.440) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=25; f1: (test=0.800) neg_log_loss: (test=-0.440) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=25; f1: (test=0.803) neg_log_loss: (test=-0.455) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=25; f1: (test=0.809) neg_log_loss: (test=-0.447) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=25; f1: (test=0.800) neg_log_loss: (test=-0.430) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=50; f1: (test=0.796) neg_log_loss: (test=-0.449) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=50; f1: (test=0.800) neg_log_loss: (test=-0.442) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=50; f1: (test=0.798) neg_log_loss: (test=-0.467) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=50; f1: (test=0.809) neg_log_loss: (test=-0.451) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=50; f1: (test=0.804) neg_log_loss: (test=-0.442) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=100; f1: (test=0.793) neg_log_loss: (test=-0.472) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=100; f1: (test=0.792) neg_log_loss: (test=-0.462) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=100; f1: (test=0.791) neg_log_loss: (test=-0.472) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=100; f1: (test=0.800) neg_log_loss: (test=-0.471) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=100; f1: (test=0.803) neg_log_loss: (test=-0.454) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=200; f1: (test=0.785) neg_log_loss: (test=-0.486) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=200; f1: (test=0.791) neg_log_loss: (test=-0.481) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=200; f1: (test=0.797) neg_log_loss: (test=-0.491) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=200; f1: (test=0.786) neg_log_loss: (test=-0.493) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=200; f1: (test=0.792) neg_log_loss: (test=-0.478) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=250; f1: (test=0.784) neg_log_loss: (test=-0.493) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=250; f1: (test=0.796) neg_log_loss: (test=-0.482) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=250; f1: (test=0.792) neg_log_loss: (test=-0.506) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=250; f1: (test=0.789) neg_log_loss: (test=-0.498) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=2, n_estimators=250; f1: (test=0.787) neg_log_loss: (test=-0.493) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=25; f1: (test=0.780) neg_log_loss: (test=-0.486) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=25; f1: (test=0.790) neg_log_loss: (test=-0.473) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=25; f1: (test=0.787) neg_log_loss: (test=-0.496) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=25; f1: (test=0.788) neg_log_loss: (test=-0.488) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=25; f1: (test=0.790) neg_log_loss: (test=-0.474) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=50; f1: (test=0.783) neg_log_loss: (test=-0.515) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=50; f1: (test=0.784) neg_log_loss: (test=-0.507) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=50; f1: (test=0.779) neg_log_loss: (test=-0.531) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=50; f1: (test=0.780) neg_log_loss: (test=-0.511) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=50; f1: (test=0.789) neg_log_loss: (test=-0.498) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=100; f1: (test=0.776) neg_log_loss: (test=-0.556) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=100; f1: (test=0.779) neg_log_loss: (test=-0.541) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=100; f1: (test=0.776) neg_log_loss: (test=-0.582) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=100; f1: (test=0.778) neg_log_loss: (test=-0.544) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=100; f1: (test=0.784) neg_log_loss: (test=-0.551) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=200; f1: (test=0.763) neg_log_loss: (test=-0.615) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=200; f1: (test=0.780) neg_log_loss: (test=-0.610) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=200; f1: (test=0.769) neg_log_loss: (test=-0.679) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gotda\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2283: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "c:\\Users\\gotda\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2283: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=200; f1: (test=0.778) neg_log_loss: (test=nan) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=200; f1: (test=0.778) neg_log_loss: (test=-0.625) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=250; f1: (test=0.773) neg_log_loss: (test=-0.635) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gotda\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2283: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "c:\\Users\\gotda\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2283: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=250; f1: (test=0.778) neg_log_loss: (test=nan) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=250; f1: (test=0.769) neg_log_loss: (test=-0.717) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gotda\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2283: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "c:\\Users\\gotda\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2283: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=250; f1: (test=0.782) neg_log_loss: (test=nan) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=4, n_estimators=250; f1: (test=0.784) neg_log_loss: (test=-0.645) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=25; f1: (test=0.764) neg_log_loss: (test=-0.563) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=25; f1: (test=0.782) neg_log_loss: (test=-0.549) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=25; f1: (test=0.776) neg_log_loss: (test=-0.579) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=25; f1: (test=0.777) neg_log_loss: (test=-0.578) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=25; f1: (test=0.780) neg_log_loss: (test=-0.567) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=50; f1: (test=0.777) neg_log_loss: (test=-0.619) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=50; f1: (test=0.792) neg_log_loss: (test=-0.596) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=50; f1: (test=0.782) neg_log_loss: (test=-0.645) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=50; f1: (test=0.771) neg_log_loss: (test=-0.635) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=50; f1: (test=0.790) neg_log_loss: (test=-0.615) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=100; f1: (test=0.767) neg_log_loss: (test=-0.701) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=100; f1: (test=0.783) neg_log_loss: (test=-0.663) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=100; f1: (test=0.773) neg_log_loss: (test=-0.728) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=100; f1: (test=0.776) neg_log_loss: (test=-0.694) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=100; f1: (test=0.779) neg_log_loss: (test=-0.667) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=200; f1: (test=0.772) neg_log_loss: (test=-0.768) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=200; f1: (test=0.783) neg_log_loss: (test=-0.731) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=200; f1: (test=0.774) neg_log_loss: (test=-0.813) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=200; f1: (test=0.773) neg_log_loss: (test=-0.763) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=200; f1: (test=0.775) neg_log_loss: (test=-0.720) total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gotda\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2283: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "c:\\Users\\gotda\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2283: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=250; f1: (test=0.774) neg_log_loss: (test=nan) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=250; f1: (test=0.785) neg_log_loss: (test=-0.756) total time=   0.5s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=250; f1: (test=0.777) neg_log_loss: (test=-0.847) total time=   0.5s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=250; f1: (test=0.779) neg_log_loss: (test=-0.774) total time=   0.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=8, n_estimators=250; f1: (test=0.776) neg_log_loss: (test=-0.739) total time=   0.5s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=25; f1: (test=0.776) neg_log_loss: (test=-0.611) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=25; f1: (test=0.786) neg_log_loss: (test=-0.600) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=25; f1: (test=0.764) neg_log_loss: (test=-0.684) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=25; f1: (test=0.784) neg_log_loss: (test=-0.605) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=25; f1: (test=0.786) neg_log_loss: (test=-0.587) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=50; f1: (test=0.775) neg_log_loss: (test=-0.667) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=50; f1: (test=0.784) neg_log_loss: (test=-0.644) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=50; f1: (test=0.764) neg_log_loss: (test=-0.748) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=50; f1: (test=0.781) neg_log_loss: (test=-0.642) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=50; f1: (test=0.788) neg_log_loss: (test=-0.630) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=100; f1: (test=0.764) neg_log_loss: (test=-0.734) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=100; f1: (test=0.785) neg_log_loss: (test=-0.694) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=100; f1: (test=0.763) neg_log_loss: (test=-0.813) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=100; f1: (test=0.785) neg_log_loss: (test=-0.701) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=100; f1: (test=0.785) neg_log_loss: (test=-0.675) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=200; f1: (test=0.765) neg_log_loss: (test=-0.773) total time=   0.7s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=200; f1: (test=0.789) neg_log_loss: (test=-0.737) total time=   0.7s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=200; f1: (test=0.763) neg_log_loss: (test=-0.870) total time=   0.8s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=200; f1: (test=0.782) neg_log_loss: (test=-0.738) total time=   1.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=200; f1: (test=0.788) neg_log_loss: (test=-0.723) total time=   0.8s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=250; f1: (test=0.765) neg_log_loss: (test=-0.773) total time=   1.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=250; f1: (test=0.790) neg_log_loss: (test=-0.749) total time=   0.9s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=250; f1: (test=0.763) neg_log_loss: (test=-0.870) total time=   0.9s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=250; f1: (test=0.782) neg_log_loss: (test=-0.738) total time=   0.9s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=16, n_estimators=250; f1: (test=0.788) neg_log_loss: (test=-0.723) total time=   0.9s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=25; f1: (test=0.676) neg_log_loss: (test=-0.687) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=25; f1: (test=0.656) neg_log_loss: (test=-0.687) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=25; f1: (test=0.654) neg_log_loss: (test=-0.687) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=25; f1: (test=0.669) neg_log_loss: (test=-0.687) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=25; f1: (test=0.679) neg_log_loss: (test=-0.687) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=50; f1: (test=0.676) neg_log_loss: (test=-0.680) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=50; f1: (test=0.656) neg_log_loss: (test=-0.681) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=50; f1: (test=0.654) neg_log_loss: (test=-0.681) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=50; f1: (test=0.669) neg_log_loss: (test=-0.681) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=50; f1: (test=0.679) neg_log_loss: (test=-0.680) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=100; f1: (test=0.676) neg_log_loss: (test=-0.669) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=100; f1: (test=0.656) neg_log_loss: (test=-0.669) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=100; f1: (test=0.654) neg_log_loss: (test=-0.669) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=100; f1: (test=0.669) neg_log_loss: (test=-0.669) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=100; f1: (test=0.679) neg_log_loss: (test=-0.668) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=200; f1: (test=0.676) neg_log_loss: (test=-0.648) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=200; f1: (test=0.656) neg_log_loss: (test=-0.649) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=200; f1: (test=0.654) neg_log_loss: (test=-0.650) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=200; f1: (test=0.669) neg_log_loss: (test=-0.649) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=200; f1: (test=0.679) neg_log_loss: (test=-0.647) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=250; f1: (test=0.676) neg_log_loss: (test=-0.639) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=250; f1: (test=0.656) neg_log_loss: (test=-0.641) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=250; f1: (test=0.654) neg_log_loss: (test=-0.641) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=250; f1: (test=0.669) neg_log_loss: (test=-0.641) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=2, n_estimators=250; f1: (test=0.679) neg_log_loss: (test=-0.637) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=25; f1: (test=0.787) neg_log_loss: (test=-0.684) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=25; f1: (test=0.773) neg_log_loss: (test=-0.684) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=25; f1: (test=0.781) neg_log_loss: (test=-0.684) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=25; f1: (test=0.771) neg_log_loss: (test=-0.685) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=25; f1: (test=0.797) neg_log_loss: (test=-0.684) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=50; f1: (test=0.791) neg_log_loss: (test=-0.676) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=50; f1: (test=0.773) neg_log_loss: (test=-0.676) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=50; f1: (test=0.781) neg_log_loss: (test=-0.676) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=50; f1: (test=0.770) neg_log_loss: (test=-0.676) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=50; f1: (test=0.801) neg_log_loss: (test=-0.675) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=100; f1: (test=0.781) neg_log_loss: (test=-0.660) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=100; f1: (test=0.774) neg_log_loss: (test=-0.660) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=100; f1: (test=0.781) neg_log_loss: (test=-0.660) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=100; f1: (test=0.770) neg_log_loss: (test=-0.661) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=100; f1: (test=0.806) neg_log_loss: (test=-0.659) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=200; f1: (test=0.788) neg_log_loss: (test=-0.633) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=200; f1: (test=0.782) neg_log_loss: (test=-0.633) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=200; f1: (test=0.780) neg_log_loss: (test=-0.633) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=200; f1: (test=0.771) neg_log_loss: (test=-0.635) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=200; f1: (test=0.782) neg_log_loss: (test=-0.630) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=250; f1: (test=0.792) neg_log_loss: (test=-0.621) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=250; f1: (test=0.783) neg_log_loss: (test=-0.621) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=250; f1: (test=0.789) neg_log_loss: (test=-0.621) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=250; f1: (test=0.773) neg_log_loss: (test=-0.623) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=4, n_estimators=250; f1: (test=0.785) neg_log_loss: (test=-0.617) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=25; f1: (test=0.796) neg_log_loss: (test=-0.683) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=25; f1: (test=0.799) neg_log_loss: (test=-0.683) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=25; f1: (test=0.792) neg_log_loss: (test=-0.683) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=25; f1: (test=0.790) neg_log_loss: (test=-0.683) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=25; f1: (test=0.804) neg_log_loss: (test=-0.682) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=50; f1: (test=0.796) neg_log_loss: (test=-0.673) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=50; f1: (test=0.799) neg_log_loss: (test=-0.673) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=50; f1: (test=0.798) neg_log_loss: (test=-0.673) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=50; f1: (test=0.789) neg_log_loss: (test=-0.673) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=50; f1: (test=0.804) neg_log_loss: (test=-0.672) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=100; f1: (test=0.789) neg_log_loss: (test=-0.655) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=100; f1: (test=0.800) neg_log_loss: (test=-0.654) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=100; f1: (test=0.802) neg_log_loss: (test=-0.655) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=100; f1: (test=0.789) neg_log_loss: (test=-0.655) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=100; f1: (test=0.805) neg_log_loss: (test=-0.653) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=200; f1: (test=0.798) neg_log_loss: (test=-0.624) total time=   0.6s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=200; f1: (test=0.800) neg_log_loss: (test=-0.622) total time=   0.6s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=200; f1: (test=0.799) neg_log_loss: (test=-0.623) total time=   0.6s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=200; f1: (test=0.792) neg_log_loss: (test=-0.624) total time=   0.6s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=200; f1: (test=0.807) neg_log_loss: (test=-0.620) total time=   0.6s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=250; f1: (test=0.798) neg_log_loss: (test=-0.610) total time=   0.7s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=250; f1: (test=0.801) neg_log_loss: (test=-0.608) total time=   0.7s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=250; f1: (test=0.799) neg_log_loss: (test=-0.609) total time=   0.7s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=250; f1: (test=0.794) neg_log_loss: (test=-0.610) total time=   0.7s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=8, n_estimators=250; f1: (test=0.808) neg_log_loss: (test=-0.606) total time=   0.7s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=25; f1: (test=0.779) neg_log_loss: (test=-0.683) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=25; f1: (test=0.787) neg_log_loss: (test=-0.682) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=25; f1: (test=0.764) neg_log_loss: (test=-0.683) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=25; f1: (test=0.775) neg_log_loss: (test=-0.683) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=25; f1: (test=0.783) neg_log_loss: (test=-0.682) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=50; f1: (test=0.783) neg_log_loss: (test=-0.673) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=50; f1: (test=0.787) neg_log_loss: (test=-0.672) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=50; f1: (test=0.772) neg_log_loss: (test=-0.673) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=50; f1: (test=0.781) neg_log_loss: (test=-0.673) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=50; f1: (test=0.786) neg_log_loss: (test=-0.672) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=100; f1: (test=0.780) neg_log_loss: (test=-0.654) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=100; f1: (test=0.790) neg_log_loss: (test=-0.653) total time=   0.5s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=100; f1: (test=0.771) neg_log_loss: (test=-0.654) total time=   0.5s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=100; f1: (test=0.785) neg_log_loss: (test=-0.655) total time=   0.5s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=100; f1: (test=0.790) neg_log_loss: (test=-0.653) total time=   0.6s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=200; f1: (test=0.784) neg_log_loss: (test=-0.622) total time=   1.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=200; f1: (test=0.786) neg_log_loss: (test=-0.621) total time=   1.3s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=200; f1: (test=0.781) neg_log_loss: (test=-0.623) total time=   1.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=200; f1: (test=0.782) neg_log_loss: (test=-0.623) total time=   1.4s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=200; f1: (test=0.787) neg_log_loss: (test=-0.620) total time=   1.4s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=250; f1: (test=0.784) neg_log_loss: (test=-0.609) total time=   1.7s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=250; f1: (test=0.793) neg_log_loss: (test=-0.608) total time=   1.6s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=250; f1: (test=0.782) neg_log_loss: (test=-0.609) total time=   1.5s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=250; f1: (test=0.782) neg_log_loss: (test=-0.610) total time=   1.8s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=16, n_estimators=250; f1: (test=0.787) neg_log_loss: (test=-0.606) total time=   1.6s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=25; f1: (test=0.676) neg_log_loss: (test=-0.639) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=25; f1: (test=0.656) neg_log_loss: (test=-0.641) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=25; f1: (test=0.654) neg_log_loss: (test=-0.641) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=25; f1: (test=0.669) neg_log_loss: (test=-0.640) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=25; f1: (test=0.679) neg_log_loss: (test=-0.637) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=50; f1: (test=0.676) neg_log_loss: (test=-0.603) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=50; f1: (test=0.656) neg_log_loss: (test=-0.606) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=50; f1: (test=0.654) neg_log_loss: (test=-0.606) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=50; f1: (test=0.669) neg_log_loss: (test=-0.606) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=50; f1: (test=0.679) neg_log_loss: (test=-0.600) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=100; f1: (test=0.698) neg_log_loss: (test=-0.559) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=100; f1: (test=0.656) neg_log_loss: (test=-0.563) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=100; f1: (test=0.654) neg_log_loss: (test=-0.563) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=100; f1: (test=0.669) neg_log_loss: (test=-0.563) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=100; f1: (test=0.679) neg_log_loss: (test=-0.552) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=200; f1: (test=0.791) neg_log_loss: (test=-0.513) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=200; f1: (test=0.779) neg_log_loss: (test=-0.515) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=200; f1: (test=0.785) neg_log_loss: (test=-0.518) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=200; f1: (test=0.785) neg_log_loss: (test=-0.517) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=200; f1: (test=0.798) neg_log_loss: (test=-0.500) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=250; f1: (test=0.793) neg_log_loss: (test=-0.501) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=250; f1: (test=0.784) neg_log_loss: (test=-0.502) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=250; f1: (test=0.790) neg_log_loss: (test=-0.505) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=250; f1: (test=0.795) neg_log_loss: (test=-0.505) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=2, n_estimators=250; f1: (test=0.803) neg_log_loss: (test=-0.486) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=25; f1: (test=0.793) neg_log_loss: (test=-0.621) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=25; f1: (test=0.783) neg_log_loss: (test=-0.621) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=25; f1: (test=0.789) neg_log_loss: (test=-0.621) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=25; f1: (test=0.773) neg_log_loss: (test=-0.623) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=25; f1: (test=0.785) neg_log_loss: (test=-0.616) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=50; f1: (test=0.794) neg_log_loss: (test=-0.572) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=50; f1: (test=0.796) neg_log_loss: (test=-0.571) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=50; f1: (test=0.778) neg_log_loss: (test=-0.573) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=50; f1: (test=0.770) neg_log_loss: (test=-0.576) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=50; f1: (test=0.787) neg_log_loss: (test=-0.566) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100; f1: (test=0.805) neg_log_loss: (test=-0.513) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100; f1: (test=0.798) neg_log_loss: (test=-0.512) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100; f1: (test=0.783) neg_log_loss: (test=-0.516) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100; f1: (test=0.792) neg_log_loss: (test=-0.520) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100; f1: (test=0.802) neg_log_loss: (test=-0.504) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=200; f1: (test=0.808) neg_log_loss: (test=-0.464) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=200; f1: (test=0.802) neg_log_loss: (test=-0.463) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=200; f1: (test=0.795) neg_log_loss: (test=-0.469) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=200; f1: (test=0.801) neg_log_loss: (test=-0.474) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=200; f1: (test=0.811) neg_log_loss: (test=-0.449) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=250; f1: (test=0.810) neg_log_loss: (test=-0.454) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=250; f1: (test=0.800) neg_log_loss: (test=-0.450) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=250; f1: (test=0.806) neg_log_loss: (test=-0.458) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=250; f1: (test=0.800) neg_log_loss: (test=-0.464) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=250; f1: (test=0.814) neg_log_loss: (test=-0.436) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=25; f1: (test=0.798) neg_log_loss: (test=-0.609) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=25; f1: (test=0.802) neg_log_loss: (test=-0.608) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=25; f1: (test=0.800) neg_log_loss: (test=-0.609) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=25; f1: (test=0.792) neg_log_loss: (test=-0.610) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=25; f1: (test=0.807) neg_log_loss: (test=-0.605) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=50; f1: (test=0.805) neg_log_loss: (test=-0.555) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=50; f1: (test=0.802) neg_log_loss: (test=-0.553) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=50; f1: (test=0.802) neg_log_loss: (test=-0.554) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=50; f1: (test=0.789) neg_log_loss: (test=-0.558) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=50; f1: (test=0.807) neg_log_loss: (test=-0.549) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=100; f1: (test=0.799) neg_log_loss: (test=-0.494) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=100; f1: (test=0.803) neg_log_loss: (test=-0.488) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=100; f1: (test=0.804) neg_log_loss: (test=-0.493) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=100; f1: (test=0.800) neg_log_loss: (test=-0.501) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=100; f1: (test=0.812) neg_log_loss: (test=-0.485) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=200; f1: (test=0.805) neg_log_loss: (test=-0.452) total time=   0.6s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=200; f1: (test=0.804) neg_log_loss: (test=-0.442) total time=   0.6s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=200; f1: (test=0.800) neg_log_loss: (test=-0.453) total time=   0.7s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=200; f1: (test=0.798) neg_log_loss: (test=-0.461) total time=   0.7s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=200; f1: (test=0.815) neg_log_loss: (test=-0.436) total time=   0.6s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=250; f1: (test=0.803) neg_log_loss: (test=-0.445) total time=   0.7s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=250; f1: (test=0.802) neg_log_loss: (test=-0.435) total time=   0.7s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=250; f1: (test=0.804) neg_log_loss: (test=-0.447) total time=   0.7s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=250; f1: (test=0.801) neg_log_loss: (test=-0.455) total time=   0.7s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=250; f1: (test=0.812) neg_log_loss: (test=-0.428) total time=   0.7s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=25; f1: (test=0.785) neg_log_loss: (test=-0.608) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=25; f1: (test=0.793) neg_log_loss: (test=-0.607) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=25; f1: (test=0.779) neg_log_loss: (test=-0.609) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=25; f1: (test=0.781) neg_log_loss: (test=-0.609) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=25; f1: (test=0.790) neg_log_loss: (test=-0.605) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=50; f1: (test=0.785) neg_log_loss: (test=-0.555) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=50; f1: (test=0.792) neg_log_loss: (test=-0.552) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=50; f1: (test=0.782) neg_log_loss: (test=-0.556) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=50; f1: (test=0.786) neg_log_loss: (test=-0.558) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=50; f1: (test=0.789) neg_log_loss: (test=-0.550) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=100; f1: (test=0.788) neg_log_loss: (test=-0.495) total time=   0.6s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=100; f1: (test=0.791) neg_log_loss: (test=-0.490) total time=   0.6s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=100; f1: (test=0.784) neg_log_loss: (test=-0.500) total time=   0.6s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=100; f1: (test=0.791) neg_log_loss: (test=-0.502) total time=   0.6s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=100; f1: (test=0.801) neg_log_loss: (test=-0.489) total time=   0.6s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=200; f1: (test=0.788) neg_log_loss: (test=-0.457) total time=   1.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=200; f1: (test=0.798) neg_log_loss: (test=-0.448) total time=   1.3s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=200; f1: (test=0.783) neg_log_loss: (test=-0.468) total time=   1.3s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=200; f1: (test=0.792) neg_log_loss: (test=-0.469) total time=   1.3s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=200; f1: (test=0.801) neg_log_loss: (test=-0.445) total time=   1.3s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=250; f1: (test=0.788) neg_log_loss: (test=-0.455) total time=   1.7s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=250; f1: (test=0.795) neg_log_loss: (test=-0.444) total time=   1.6s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=250; f1: (test=0.782) neg_log_loss: (test=-0.466) total time=   1.5s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=250; f1: (test=0.791) neg_log_loss: (test=-0.465) total time=   1.6s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=16, n_estimators=250; f1: (test=0.805) neg_log_loss: (test=-0.441) total time=   1.6s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=25; f1: (test=0.792) neg_log_loss: (test=-0.500) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=25; f1: (test=0.776) neg_log_loss: (test=-0.501) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=25; f1: (test=0.789) neg_log_loss: (test=-0.504) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=25; f1: (test=0.801) neg_log_loss: (test=-0.503) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=25; f1: (test=0.808) neg_log_loss: (test=-0.484) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=50; f1: (test=0.796) neg_log_loss: (test=-0.470) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=50; f1: (test=0.794) neg_log_loss: (test=-0.465) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=50; f1: (test=0.802) neg_log_loss: (test=-0.473) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=50; f1: (test=0.793) neg_log_loss: (test=-0.473) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=50; f1: (test=0.814) neg_log_loss: (test=-0.449) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=100; f1: (test=0.807) neg_log_loss: (test=-0.450) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=100; f1: (test=0.805) neg_log_loss: (test=-0.442) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=100; f1: (test=0.801) neg_log_loss: (test=-0.453) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=100; f1: (test=0.800) neg_log_loss: (test=-0.454) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=100; f1: (test=0.816) neg_log_loss: (test=-0.427) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=200; f1: (test=0.805) neg_log_loss: (test=-0.440) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=200; f1: (test=0.810) neg_log_loss: (test=-0.431) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=200; f1: (test=0.802) neg_log_loss: (test=-0.446) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=200; f1: (test=0.806) neg_log_loss: (test=-0.444) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=200; f1: (test=0.809) neg_log_loss: (test=-0.418) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=250; f1: (test=0.801) neg_log_loss: (test=-0.438) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=250; f1: (test=0.810) neg_log_loss: (test=-0.430) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=250; f1: (test=0.803) neg_log_loss: (test=-0.447) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=250; f1: (test=0.807) neg_log_loss: (test=-0.443) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=2, n_estimators=250; f1: (test=0.815) neg_log_loss: (test=-0.418) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=25; f1: (test=0.808) neg_log_loss: (test=-0.452) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=25; f1: (test=0.802) neg_log_loss: (test=-0.447) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=25; f1: (test=0.798) neg_log_loss: (test=-0.458) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=25; f1: (test=0.799) neg_log_loss: (test=-0.464) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=25; f1: (test=0.814) neg_log_loss: (test=-0.435) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=50; f1: (test=0.808) neg_log_loss: (test=-0.438) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=50; f1: (test=0.807) neg_log_loss: (test=-0.430) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=50; f1: (test=0.805) neg_log_loss: (test=-0.446) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=50; f1: (test=0.805) neg_log_loss: (test=-0.450) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=50; f1: (test=0.812) neg_log_loss: (test=-0.419) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100; f1: (test=0.806) neg_log_loss: (test=-0.435) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100; f1: (test=0.811) neg_log_loss: (test=-0.425) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100; f1: (test=0.811) neg_log_loss: (test=-0.442) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100; f1: (test=0.807) neg_log_loss: (test=-0.446) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100; f1: (test=0.812) neg_log_loss: (test=-0.414) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=200; f1: (test=0.799) neg_log_loss: (test=-0.436) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=200; f1: (test=0.803) neg_log_loss: (test=-0.426) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=200; f1: (test=0.804) neg_log_loss: (test=-0.450) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=200; f1: (test=0.809) neg_log_loss: (test=-0.447) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=200; f1: (test=0.809) neg_log_loss: (test=-0.421) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=250; f1: (test=0.804) neg_log_loss: (test=-0.436) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=250; f1: (test=0.798) neg_log_loss: (test=-0.430) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=250; f1: (test=0.801) neg_log_loss: (test=-0.453) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=250; f1: (test=0.804) neg_log_loss: (test=-0.449) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=250; f1: (test=0.805) neg_log_loss: (test=-0.424) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=25; f1: (test=0.797) neg_log_loss: (test=-0.447) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=25; f1: (test=0.801) neg_log_loss: (test=-0.435) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=25; f1: (test=0.805) neg_log_loss: (test=-0.446) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=25; f1: (test=0.790) neg_log_loss: (test=-0.455) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=25; f1: (test=0.813) neg_log_loss: (test=-0.427) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=50; f1: (test=0.798) neg_log_loss: (test=-0.442) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=50; f1: (test=0.804) neg_log_loss: (test=-0.430) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=50; f1: (test=0.807) neg_log_loss: (test=-0.444) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=50; f1: (test=0.796) neg_log_loss: (test=-0.453) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=50; f1: (test=0.807) neg_log_loss: (test=-0.422) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=100; f1: (test=0.795) neg_log_loss: (test=-0.450) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=100; f1: (test=0.806) neg_log_loss: (test=-0.433) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=100; f1: (test=0.797) neg_log_loss: (test=-0.457) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=100; f1: (test=0.797) neg_log_loss: (test=-0.455) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=100; f1: (test=0.802) neg_log_loss: (test=-0.429) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=200; f1: (test=0.789) neg_log_loss: (test=-0.462) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=200; f1: (test=0.799) neg_log_loss: (test=-0.449) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=200; f1: (test=0.795) neg_log_loss: (test=-0.478) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=200; f1: (test=0.795) neg_log_loss: (test=-0.464) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=200; f1: (test=0.799) neg_log_loss: (test=-0.447) total time=   0.4s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=250; f1: (test=0.787) neg_log_loss: (test=-0.470) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=250; f1: (test=0.797) neg_log_loss: (test=-0.457) total time=   0.6s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=250; f1: (test=0.796) neg_log_loss: (test=-0.488) total time=   0.5s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=250; f1: (test=0.796) neg_log_loss: (test=-0.469) total time=   0.5s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=250; f1: (test=0.801) neg_log_loss: (test=-0.455) total time=   0.6s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=25; f1: (test=0.789) neg_log_loss: (test=-0.454) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=25; f1: (test=0.803) neg_log_loss: (test=-0.440) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=25; f1: (test=0.781) neg_log_loss: (test=-0.465) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=25; f1: (test=0.784) neg_log_loss: (test=-0.467) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=25; f1: (test=0.805) neg_log_loss: (test=-0.440) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=50; f1: (test=0.795) neg_log_loss: (test=-0.465) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=50; f1: (test=0.798) neg_log_loss: (test=-0.449) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=50; f1: (test=0.783) neg_log_loss: (test=-0.480) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=50; f1: (test=0.789) neg_log_loss: (test=-0.467) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=50; f1: (test=0.806) neg_log_loss: (test=-0.443) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=100; f1: (test=0.785) neg_log_loss: (test=-0.486) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=100; f1: (test=0.793) neg_log_loss: (test=-0.462) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=100; f1: (test=0.785) neg_log_loss: (test=-0.504) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=100; f1: (test=0.789) neg_log_loss: (test=-0.478) total time=   0.5s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=100; f1: (test=0.803) neg_log_loss: (test=-0.457) total time=   0.4s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=200; f1: (test=0.780) neg_log_loss: (test=-0.519) total time=   0.9s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=200; f1: (test=0.792) neg_log_loss: (test=-0.489) total time=   0.9s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=200; f1: (test=0.784) neg_log_loss: (test=-0.549) total time=   0.9s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=200; f1: (test=0.789) neg_log_loss: (test=-0.505) total time=   0.9s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=200; f1: (test=0.794) neg_log_loss: (test=-0.488) total time=   0.9s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=250; f1: (test=0.780) neg_log_loss: (test=-0.533) total time=   1.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=250; f1: (test=0.789) neg_log_loss: (test=-0.500) total time=   1.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=250; f1: (test=0.782) neg_log_loss: (test=-0.565) total time=   1.3s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=250; f1: (test=0.792) neg_log_loss: (test=-0.517) total time=   1.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=16, n_estimators=250; f1: (test=0.796) neg_log_loss: (test=-0.500) total time=   1.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=25; f1: (test=0.801) neg_log_loss: (test=-0.440) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=25; f1: (test=0.800) neg_log_loss: (test=-0.440) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=25; f1: (test=0.803) neg_log_loss: (test=-0.455) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=25; f1: (test=0.809) neg_log_loss: (test=-0.447) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=25; f1: (test=0.800) neg_log_loss: (test=-0.430) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=50; f1: (test=0.796) neg_log_loss: (test=-0.449) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=50; f1: (test=0.800) neg_log_loss: (test=-0.442) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=50; f1: (test=0.798) neg_log_loss: (test=-0.467) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=50; f1: (test=0.809) neg_log_loss: (test=-0.451) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=50; f1: (test=0.804) neg_log_loss: (test=-0.442) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=100; f1: (test=0.793) neg_log_loss: (test=-0.472) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=100; f1: (test=0.792) neg_log_loss: (test=-0.462) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=100; f1: (test=0.791) neg_log_loss: (test=-0.472) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=100; f1: (test=0.800) neg_log_loss: (test=-0.471) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=100; f1: (test=0.796) neg_log_loss: (test=-0.450) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=200; f1: (test=0.786) neg_log_loss: (test=-0.483) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=200; f1: (test=0.790) neg_log_loss: (test=-0.485) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=200; f1: (test=0.797) neg_log_loss: (test=-0.491) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=200; f1: (test=0.793) neg_log_loss: (test=-0.490) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=200; f1: (test=0.791) neg_log_loss: (test=-0.477) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=250; f1: (test=0.788) neg_log_loss: (test=-0.497) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=250; f1: (test=0.793) neg_log_loss: (test=-0.494) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=250; f1: (test=0.792) neg_log_loss: (test=-0.506) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=250; f1: (test=0.786) neg_log_loss: (test=-0.494) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=2, n_estimators=250; f1: (test=0.790) neg_log_loss: (test=-0.481) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=25; f1: (test=0.787) neg_log_loss: (test=-0.480) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=25; f1: (test=0.790) neg_log_loss: (test=-0.473) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=25; f1: (test=0.788) neg_log_loss: (test=-0.494) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=25; f1: (test=0.783) neg_log_loss: (test=-0.483) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=25; f1: (test=0.787) neg_log_loss: (test=-0.469) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=50; f1: (test=0.776) neg_log_loss: (test=-0.528) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=50; f1: (test=0.777) neg_log_loss: (test=-0.497) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=50; f1: (test=0.781) neg_log_loss: (test=-0.526) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=50; f1: (test=0.785) neg_log_loss: (test=-0.517) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=50; f1: (test=0.787) neg_log_loss: (test=-0.504) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=100; f1: (test=0.773) neg_log_loss: (test=-0.569) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=100; f1: (test=0.783) neg_log_loss: (test=-0.532) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=100; f1: (test=0.773) neg_log_loss: (test=-0.587) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=100; f1: (test=0.775) neg_log_loss: (test=-0.564) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=100; f1: (test=0.783) neg_log_loss: (test=-0.547) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=200; f1: (test=0.767) neg_log_loss: (test=-0.646) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=200; f1: (test=0.780) neg_log_loss: (test=-0.607) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=200; f1: (test=0.768) neg_log_loss: (test=-0.665) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=200; f1: (test=0.767) neg_log_loss: (test=-0.627) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=200; f1: (test=0.775) neg_log_loss: (test=-0.608) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=250; f1: (test=0.769) neg_log_loss: (test=-0.651) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=250; f1: (test=0.778) neg_log_loss: (test=-0.633) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=250; f1: (test=0.769) neg_log_loss: (test=-0.689) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=250; f1: (test=0.770) neg_log_loss: (test=-0.629) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=4, n_estimators=250; f1: (test=0.775) neg_log_loss: (test=-0.608) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=25; f1: (test=0.767) neg_log_loss: (test=-0.556) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=25; f1: (test=0.787) neg_log_loss: (test=-0.526) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=25; f1: (test=0.768) neg_log_loss: (test=-0.601) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=25; f1: (test=0.794) neg_log_loss: (test=-0.536) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=25; f1: (test=0.786) neg_log_loss: (test=-0.531) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=50; f1: (test=0.769) neg_log_loss: (test=-0.621) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=50; f1: (test=0.794) neg_log_loss: (test=-0.582) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=50; f1: (test=0.768) neg_log_loss: (test=-0.672) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=50; f1: (test=0.784) neg_log_loss: (test=-0.574) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=50; f1: (test=0.783) neg_log_loss: (test=-0.594) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=100; f1: (test=0.767) neg_log_loss: (test=-0.658) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=100; f1: (test=0.787) neg_log_loss: (test=-0.609) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=100; f1: (test=0.772) neg_log_loss: (test=-0.739) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=100; f1: (test=0.784) neg_log_loss: (test=-0.606) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=100; f1: (test=0.781) neg_log_loss: (test=-0.638) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=200; f1: (test=0.767) neg_log_loss: (test=-0.658) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=200; f1: (test=0.787) neg_log_loss: (test=-0.609) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=200; f1: (test=0.774) neg_log_loss: (test=-0.750) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=200; f1: (test=0.784) neg_log_loss: (test=-0.606) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=200; f1: (test=0.781) neg_log_loss: (test=-0.638) total time=   0.4s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=250; f1: (test=0.767) neg_log_loss: (test=-0.658) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=250; f1: (test=0.787) neg_log_loss: (test=-0.609) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=250; f1: (test=0.774) neg_log_loss: (test=-0.750) total time=   0.5s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=250; f1: (test=0.784) neg_log_loss: (test=-0.606) total time=   0.5s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=8, n_estimators=250; f1: (test=0.781) neg_log_loss: (test=-0.638) total time=   0.5s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=25; f1: (test=0.770) neg_log_loss: (test=-0.608) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=25; f1: (test=0.781) neg_log_loss: (test=-0.604) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=25; f1: (test=0.768) neg_log_loss: (test=-0.661) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=25; f1: (test=0.789) neg_log_loss: (test=-0.585) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=25; f1: (test=0.781) neg_log_loss: (test=-0.608) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=50; f1: (test=0.772) neg_log_loss: (test=-0.647) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=50; f1: (test=0.783) neg_log_loss: (test=-0.637) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=50; f1: (test=0.771) neg_log_loss: (test=-0.707) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=50; f1: (test=0.793) neg_log_loss: (test=-0.615) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=50; f1: (test=0.776) neg_log_loss: (test=-0.638) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=100; f1: (test=0.774) neg_log_loss: (test=-0.650) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=100; f1: (test=0.780) neg_log_loss: (test=-0.650) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=100; f1: (test=0.772) neg_log_loss: (test=-0.715) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=100; f1: (test=0.794) neg_log_loss: (test=-0.619) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=100; f1: (test=0.776) neg_log_loss: (test=-0.638) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=200; f1: (test=0.774) neg_log_loss: (test=-0.650) total time=   0.8s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=200; f1: (test=0.780) neg_log_loss: (test=-0.650) total time=   0.8s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=200; f1: (test=0.772) neg_log_loss: (test=-0.715) total time=   0.8s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=200; f1: (test=0.794) neg_log_loss: (test=-0.619) total time=   0.7s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=200; f1: (test=0.776) neg_log_loss: (test=-0.638) total time=   0.7s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=250; f1: (test=0.774) neg_log_loss: (test=-0.650) total time=   0.9s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=250; f1: (test=0.780) neg_log_loss: (test=-0.650) total time=   0.9s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=250; f1: (test=0.772) neg_log_loss: (test=-0.715) total time=   0.9s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=250; f1: (test=0.794) neg_log_loss: (test=-0.619) total time=   0.9s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=16, n_estimators=250; f1: (test=0.776) neg_log_loss: (test=-0.638) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gotda\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [-0.68671049 -0.68053477 -0.66900234 -0.64870724 -0.63977799 -0.68428399\n",
      " -0.67586369 -0.66021584 -0.63280608 -0.62060042 -0.68279393 -0.67294472\n",
      " -0.65460153 -0.6227123  -0.60869305 -0.68259324 -0.67256703 -0.65394011\n",
      " -0.62207131 -0.60825835 -0.63961913 -0.60412319 -0.56000782 -0.51247691\n",
      " -0.49982065 -0.62034386 -0.57150819 -0.51312602 -0.46373324 -0.45249543\n",
      " -0.60843969 -0.55380228 -0.49214245 -0.44890485 -0.44187062 -0.60799435\n",
      " -0.55433163 -0.49566018 -0.45829318 -0.45484066 -0.49824909 -0.46616137\n",
      " -0.44513935 -0.43566444 -0.43484409 -0.45110469 -0.43637327 -0.43186059\n",
      " -0.43570522 -0.4378903  -0.44249531 -0.43817236 -0.44477291 -0.45892146\n",
      " -0.46708158 -0.45417027 -0.46272178 -0.47971985 -0.51109912 -0.52424826\n",
      " -0.44240877 -0.45017908 -0.46635027 -0.48594522 -0.49448587 -0.48356531\n",
      " -0.51244121 -0.55514957         nan         nan -0.56703098 -0.62207818\n",
      " -0.69070277 -0.75910946         nan -0.6175009  -0.66611371 -0.72331554\n",
      " -0.76839161 -0.77082184 -0.68671049 -0.68053477 -0.66900234 -0.64870724\n",
      " -0.63977799 -0.68428399 -0.67586369 -0.66021584 -0.6327978  -0.62059568\n",
      " -0.68279487 -0.67294571 -0.65459805 -0.62269322 -0.60866795 -0.68258795\n",
      " -0.67255495 -0.6539102  -0.62199394 -0.60814054 -0.63961913 -0.60412319\n",
      " -0.56000782 -0.51247691 -0.49982065 -0.62034015 -0.57150903 -0.51312745\n",
      " -0.46375786 -0.45252293 -0.60842208 -0.55373421 -0.49215774 -0.44885994\n",
      " -0.44188981 -0.60788846 -0.55417347 -0.49509501 -0.45767194 -0.45422638\n",
      " -0.49824909 -0.46616137 -0.44515831 -0.43595749 -0.43505503 -0.45111951\n",
      " -0.43650167 -0.43237446 -0.43586303 -0.43833942 -0.44192506 -0.43818063\n",
      " -0.44474163 -0.4599252  -0.46783312 -0.45312284 -0.46086157 -0.47732003\n",
      " -0.50994978 -0.52301748 -0.44240877 -0.45017908 -0.4654393  -0.48514153\n",
      " -0.49451839 -0.47972524 -0.51413158 -0.55997027 -0.63036278 -0.64185509\n",
      " -0.55004862 -0.60843583 -0.64997801 -0.65221016 -0.65221016 -0.61297465\n",
      " -0.6485581  -0.65411703 -0.65411703 -0.65411703]\n",
      "  warnings.warn(\n",
      "c:\\Users\\gotda\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:935: RuntimeWarning: invalid value encountered in cast\n",
      "  results[\"rank_%s\" % key_name] = np.asarray(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=42, ...),\n",
       "             param_grid={'gamma': [0.01, 0.1],\n",
       "                         'learning_rate': [0.001, 0.01, 0.1, 1],\n",
       "                         'max_depth': [2, 4, 8, 16],\n",
       "                         'n_estimators': [25, 50, 100, 200, 250]},\n",
       "             refit='neg_log_loss', scoring=['neg_log_loss', 'f1'], verbose=4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tBest Score\tBest Paramaters\n",
      "Forest\t-0.4387\t{'max_depth': 8, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "       XGBoost\t-0.6867\t{'gamma': 0.01, 'learning_rate': 0.001, 'max_depth': 2, 'n_estimators': 25}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model\\tBest Score\\tBest Paramaters\\nForest\\t{grid_search_forest.best_score_:0.4f}\\t{grid_search_forest.best_params_}\\n \\\n",
    "      XGBoost\\t{grid_search_xgb.best_score_:0.4f}\\t{grid_search_xgb.best_params_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.69287\n",
      "[1]\tvalidation_0-logloss:0.69259\n",
      "[2]\tvalidation_0-logloss:0.69232\n",
      "[3]\tvalidation_0-logloss:0.69204\n",
      "[4]\tvalidation_0-logloss:0.69176\n",
      "[5]\tvalidation_0-logloss:0.69149\n",
      "[6]\tvalidation_0-logloss:0.69121\n",
      "[7]\tvalidation_0-logloss:0.69094\n",
      "[8]\tvalidation_0-logloss:0.69067\n",
      "[9]\tvalidation_0-logloss:0.69039\n",
      "[10]\tvalidation_0-logloss:0.69012\n",
      "[11]\tvalidation_0-logloss:0.68985\n",
      "[12]\tvalidation_0-logloss:0.68958\n",
      "[13]\tvalidation_0-logloss:0.68931\n",
      "[14]\tvalidation_0-logloss:0.68904\n",
      "[15]\tvalidation_0-logloss:0.68877\n",
      "[16]\tvalidation_0-logloss:0.68850\n",
      "[17]\tvalidation_0-logloss:0.68823\n",
      "[18]\tvalidation_0-logloss:0.68796\n",
      "[19]\tvalidation_0-logloss:0.68769\n",
      "[20]\tvalidation_0-logloss:0.68743\n",
      "[21]\tvalidation_0-logloss:0.68716\n",
      "[22]\tvalidation_0-logloss:0.68690\n",
      "[23]\tvalidation_0-logloss:0.68663\n",
      "[24]\tvalidation_0-logloss:0.68637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gotda\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "xgb_classfier_gs = XGBClassifier(random_state=42, gamma=0.01, learning_rate=0.001, max_depth=2, n_estimators=25).fit(X_train, y_train, \n",
    "                                                                                                                     early_stopping_rounds=10,\n",
    "                                                                                                                     eval_set=[(X_val, y_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7222541690626797\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_val, xgb_classfier_gs.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_classifier_gs = RandomForestClassifier(random_state=42,\n",
    "                                                     max_depth=8, \n",
    "                                                     min_samples_split=4, \n",
    "                                                     n_estimators=200).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.780333525014376\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_val, random_forest_classifier_gs.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_preds = random_forest_classifier_gs.predict(test_data)\n",
    "\n",
    "submission_df = pd.DataFrame({\"PassengerId\": test_ids.values,\n",
    "                              \"Transported\": submission_preds,\n",
    "                            })\n",
    "\n",
    "submission_df.to_csv(\"Submission_forest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8370b45682d8b4af50cd5c75b00158423c1c1d2b63c3dd92c8e6a2ae1b47245f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
